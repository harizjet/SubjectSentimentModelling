{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h3>Library</h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general tools\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import io\n",
    "import re\n",
    "import datetime as dt\n",
    "import json\n",
    "import requests\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# preprocessing & utils\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# ml models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# others\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib.ticker import FormatStrFormatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h3>Utility Function</h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processsing\n",
    "def pipe_cleaningText(text: str) -> str:\n",
    "    txt = text.lower()\n",
    "    return txt\n",
    "\n",
    "def pipe_removeStopWords(text: str) -> str:\n",
    "    return \" \".join([w for w in word_tokenize(text) if w not in stop_words])\n",
    "\n",
    "def pipe_lemmatization(text: str) -> str:\n",
    "    txt = \"\"\n",
    "    for w in word_tokenize(text):\n",
    "        txt += lemmatizer.lemmatize(w) + ' '\n",
    "    return txt.strip()\n",
    "\n",
    "def pipe_addPos(text: str) -> str:\n",
    "    txt = \"\"\n",
    "    for w in pos_tag(word_tokenize(text)):\n",
    "        txt += '__'.join(w) + ' '\n",
    "    return txt.strip()\n",
    "\n",
    "def pipe_normalized(text: str, bin: int) -> str:\n",
    "    txt = \"\"\n",
    "    elements = word_tokenize(text)\n",
    "    n = len(elements)\n",
    "    for i, w in enumerate(elements):\n",
    "        normVal = math.floor((i / (n - 1)) * (bin - 1)) + 1 if n != 1 else 1\n",
    "        txt += w + '__' + str(normVal) + ' '\n",
    "    return txt.strip()\n",
    "\n",
    "def pipe_subjectCleaning(text: str) -> str:\n",
    "    txt = \"\"\n",
    "    for s in sent_tokenize(text):\n",
    "        for w in pos_tag(word_tokenize(s)):\n",
    "            if w[1] != 'NNP':\n",
    "                continue\n",
    "            txt += w[0] + ' '\n",
    "    return txt.strip()\n",
    "\n",
    "# feature extraction\n",
    "def feature_tfidfUni(series: pd.Series) -> (sp.sparse.csr_matrix, TfidfVectorizer):\n",
    "    tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,1))\n",
    "    tfidf_vectorizer.fit(series)\n",
    "    return tfidf_vectorizer.transform(series), tfidf_vectorizer\n",
    "\n",
    "def feature_bowUni(series: pd.Series) -> (sp.sparse.csr_matrix, CountVectorizer):\n",
    "    bow_vectorizer = CountVectorizer(ngram_range=(1,1))\n",
    "    bow_vectorizer.fit(series)\n",
    "    return bow_vectorizer.transform(series), bow_vectorizer\n",
    "\n",
    "def feature_tfidfUniBi(series: pd.Series) -> (sp.sparse.csr_matrix, TfidfVectorizer):\n",
    "    tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "    tfidf_vectorizer.fit(series)\n",
    "    return tfidf_vectorizer.transform(series), tfidf_vectorizer\n",
    "\n",
    "def feature_bowUniBi(series: pd.Series) -> (sp.sparse.csr_matrix, CountVectorizer):\n",
    "    bow_vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "    bow_vectorizer.fit(series)\n",
    "    return bow_vectorizer.transform(series), bow_vectorizer\n",
    "\n",
    "# sampling\n",
    "def balancing_upsampling(data: pd.DataFrame, target: int=None) -> pd.DataFrame:\n",
    "    group_res = data.groupby(by=['overall'])['overall'].count()\n",
    "    highest_n = max(group_res.values) if not target else target\n",
    "    thedata = data[data.overall == group_res[group_res == highest_n].index[0]] if not target else data.drop(data.index)\n",
    "    for i in group_res.index:\n",
    "        if group_res.loc[i] == highest_n:\n",
    "            continue\n",
    "        tdata = data[data.overall == i]\n",
    "        sample_ind = np.random.choice(tdata.index, highest_n - group_res.loc[i], replace=True)\n",
    "        thedata = pd.concat([thedata, tdata, tdata.loc[sample_ind]])\n",
    "    return thedata\n",
    "\n",
    "def balancing_downsampling(data: pd.DataFrame, target: int=None) -> pd.DataFrame:\n",
    "    group_res = data.groupby(by=['overall'])['overall'].count()\n",
    "    lowest_n = min(group_res.values) if not target else target\n",
    "    thedata = data[data.overall == group_res[group_res == lowest_n].index[0]] if not target else data.drop(data.index)\n",
    "    for i in group_res.index:\n",
    "        if group_res.loc[i] == lowest_n:\n",
    "            continue\n",
    "        tdata = data[data.overall == i]\n",
    "        sample_ind = np.random.choice(tdata.index, lowest_n, replace=False)\n",
    "        thedata = pd.concat([thedata, tdata.loc[sample_ind]])\n",
    "    return thedata\n",
    "\n",
    "# testing\n",
    "def accuracyTrainTest(model, trainX: np.array, trainY: np.array, valX: np.array, valY: np.array, testX: np.array, testY: np.array) -> (float, float, float):\n",
    "    mod = model.fit(trainX, trainY)\n",
    "    yfit = mod.predict(trainX)\n",
    "    ypredVal = mod.predict(valX)\n",
    "    ypredTest = mod.predict(testX)\n",
    "    \n",
    "    # train result, validation result, test result\n",
    "    return accuracy_score(trainY, yfit), accuracy_score(valY, ypredVal), accuracy_score(testY, ypredTest)\n",
    "    \n",
    "def loop_testing(model, n_test: int, xArr: sp.sparse.csr_matrix, yArr: np.array, testXArr: sp.sparse.csr_matrix, testYArr: np.array) -> dict[str: list([float, float])]:\n",
    "    thedict = {}\n",
    "\n",
    "    i = 0\n",
    "    n = xArr.shape[0]\n",
    "    n_sample = math.ceil(n / n_test)\n",
    "    x_sam, y_sam = np.array([]), np.array([])\n",
    "    while i < n_test:\n",
    "        percent_sample = n_sample/xArr.shape[0]\n",
    "        if percent_sample >= 1:\n",
    "            xmain, ymain = xArr, yArr\n",
    "        else:\n",
    "            xmain, xArr, ymain, yArr = train_test_split(xArr, yArr, train_size=percent_sample, stratify=yArr)\n",
    "        \n",
    "        x_sam = sp.sparse.vstack((x_sam, xmain)) if x_sam.shape[0] != 0 else xmain\n",
    "        y_sam = np.hstack((y_sam, ymain)) if y_sam.shape[0] != 0 else ymain\n",
    "        xtrain, xtest, ytrain, ytest = train_test_split(x_sam, y_sam, train_size=0.9, stratify=y_sam)\n",
    "\n",
    "        resTrain, resVal, resTest = accuracyTrainTest(model, xtrain, ytrain, xtest, ytest, testXArr, testYArr)\n",
    "        thedict[x_sam.shape[0]] = [resTrain, resVal, resTest]\n",
    "\n",
    "        i += 1\n",
    "    return thedict\n",
    "\n",
    "# visualization\n",
    "def show_result(ypred: np.array, ytarget: np.array) -> None:\n",
    "    report = classification_report(ypred, ytarget, labels=label)\n",
    "    conf_matrix = confusion_matrix(ypred, ytarget, labels=label)\n",
    "\n",
    "    label = ['Positive', 'Neutral', 'Negative']\n",
    "    group_names = ['True Pos', 'False Neu', 'False Neg',\n",
    "                   'False Pos', 'True Neu', 'False Neg',\n",
    "                   'False Pos, False Neu, True Neg']\n",
    "    group_percentages = ['{0:.2%}'.format(value) for value in conf_matrix.flatten() / np.sum(conf_matrix)]\n",
    "    labels = [f'{v1}\\n{v2}' for v1, v2 in zip(group_names, group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(3, 3)\n",
    "\n",
    "    df_cm = pd.DataFrame(data=conf_matrix, index=label, columns=label)\n",
    "\n",
    "    print(report)\n",
    "    fix, axe = plt.subplots(figsize=(15, 8), nrows=1, ncols=1)\n",
    "    sns.heatmap(df_cm, xticklabels=label, yticklabels=label, annot=labels, ax=axe, fmt='.0f', cmap=sns.cm.rocket_r, vmax=100*1000)\n",
    "    plt.show();\n",
    "\n",
    "def visualized_loopTesting(result_loopTesting: dict[str: list([float, float])]) -> None:\n",
    "    train_res, val_res, test_res = dict(), dict(), dict()\n",
    "    for res in result_loopTesting:\n",
    "        train_res[res] = result[res][0]\n",
    "        val_res[res] = result[res][1]\n",
    "        test_res[res] = result[res][2]\n",
    "\n",
    "    fig, axe = plt.subplots(figsize=(15, 8), nrows=1, ncols=1)\n",
    "    sns.lineplot(y=train_res.values(), x=train_res.keys() , ax=axe, label='train-result')\n",
    "    sns.lineplot(y=val_res.values(), x=val_res.keys(), ax=axe, label='val-result')\n",
    "    sns.lineplot(y=test_res.values(), x=test_res.keys(), ax=axe, label='test-result')\n",
    "    axe.set_title(\"Highest Score: {}\".format(max(test_res.values())))\n",
    "    axe.set_xlabel(\"Dataset Size\")\n",
    "    axe.set_ylabel(\"Accuracy\")\n",
    "    axe.xaxis.set_major_formatter(FormatStrFormatter('%.0f'))\n",
    "    plt.show();\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h3>Exploration</h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../data/Amazon_GroceryandGourmetFood.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "      <th>style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>06 4, 2013</td>\n",
       "      <td>ALP49FBWT4I7V</td>\n",
       "      <td>1888861614</td>\n",
       "      <td>Lori</td>\n",
       "      <td>Very pleased with my purchase. Looks exactly l...</td>\n",
       "      <td>Love it</td>\n",
       "      <td>1370304000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>05 23, 2014</td>\n",
       "      <td>A1KPIZOCLB9FZ8</td>\n",
       "      <td>1888861614</td>\n",
       "      <td>BK Shopper</td>\n",
       "      <td>Very nicely crafted but too small. Am going to...</td>\n",
       "      <td>Nice but small</td>\n",
       "      <td>1400803200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>05 9, 2014</td>\n",
       "      <td>A2W0FA06IYAYQE</td>\n",
       "      <td>1888861614</td>\n",
       "      <td>daninethequeen</td>\n",
       "      <td>still very pretty and well made...i am super p...</td>\n",
       "      <td>the \"s\" looks like a 5, kina</td>\n",
       "      <td>1399593600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>04 20, 2014</td>\n",
       "      <td>A2PTZTCH2QUYBC</td>\n",
       "      <td>1888861614</td>\n",
       "      <td>Tammara</td>\n",
       "      <td>I got this for our wedding cake, and it was ev...</td>\n",
       "      <td>Would recommend this to a friend!</td>\n",
       "      <td>1397952000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>04 16, 2014</td>\n",
       "      <td>A2VNHGJ59N4Z90</td>\n",
       "      <td>1888861614</td>\n",
       "      <td>LaQuinta Alexander</td>\n",
       "      <td>It was just what I want to put at the top of m...</td>\n",
       "      <td>Topper</td>\n",
       "      <td>1397606400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0        5      True   06 4, 2013   ALP49FBWT4I7V  1888861614   \n",
       "1        4      True  05 23, 2014  A1KPIZOCLB9FZ8  1888861614   \n",
       "2        4      True   05 9, 2014  A2W0FA06IYAYQE  1888861614   \n",
       "3        5      True  04 20, 2014  A2PTZTCH2QUYBC  1888861614   \n",
       "4        4      True  04 16, 2014  A2VNHGJ59N4Z90  1888861614   \n",
       "\n",
       "         reviewerName                                         reviewText  \\\n",
       "0                Lori  Very pleased with my purchase. Looks exactly l...   \n",
       "1          BK Shopper  Very nicely crafted but too small. Am going to...   \n",
       "2      daninethequeen  still very pretty and well made...i am super p...   \n",
       "3             Tammara  I got this for our wedding cake, and it was ev...   \n",
       "4  LaQuinta Alexander  It was just what I want to put at the top of m...   \n",
       "\n",
       "                             summary  unixReviewTime vote image style  \n",
       "0                            Love it      1370304000  NaN   NaN   NaN  \n",
       "1                     Nice but small      1400803200  NaN   NaN   NaN  \n",
       "2       the \"s\" looks like a 5, kina      1399593600  NaN   NaN   NaN  \n",
       "3  Would recommend this to a friend!      1397952000  NaN   NaN   NaN  \n",
       "4                             Topper      1397606400  NaN   NaN   NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.074160e+06</td>\n",
       "      <td>5.074160e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.314708e+00</td>\n",
       "      <td>1.446592e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.249303e+00</td>\n",
       "      <td>6.227839e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.613728e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.416096e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.456790e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.491782e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.538870e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            overall  unixReviewTime\n",
       "count  5.074160e+06    5.074160e+06\n",
       "mean   4.314708e+00    1.446592e+09\n",
       "std    1.249303e+00    6.227839e+07\n",
       "min    1.000000e+00    9.613728e+08\n",
       "25%    4.000000e+00    1.416096e+09\n",
       "50%    5.000000e+00    1.456790e+09\n",
       "75%    5.000000e+00    1.491782e+09\n",
       "max    5.000000e+00    1.538870e+09"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall                 0\n",
       "verified                0\n",
       "reviewTime              0\n",
       "reviewerID              0\n",
       "asin                    0\n",
       "reviewerName          355\n",
       "reviewText           2883\n",
       "summary              1327\n",
       "unixReviewTime          0\n",
       "vote              4414688\n",
       "image             5003225\n",
       "style             2798836\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Very pleased with my purchase. Looks exactly l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Very nicely crafted but too small. Am going to...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>still very pretty and well made...i am super p...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I got this for our wedding cake, and it was ev...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was just what I want to put at the top of m...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall\n",
       "0  Very pleased with my purchase. Looks exactly l...        5\n",
       "1  Very nicely crafted but too small. Am going to...        4\n",
       "2  still very pretty and well made...i am super p...        4\n",
       "3  I got this for our wedding cake, and it was ev...        5\n",
       "4  It was just what I want to put at the top of m...        4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdata = df[['reviewText', 'overall']]\n",
    "dfdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdata.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewText    0\n",
       "overall       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdata.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_n = 500 * 1000\n",
    "dfdataMain, _ = train_test_split(dfdata, train_size=target_n / dfdata.shape[0], stratify=dfdata['overall'], random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdataMain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h3>Process</h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "46bc6b800f911b1c1d0f43a06dbc3139270a12e6ebc6e060d97d05b2a2df1825"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
