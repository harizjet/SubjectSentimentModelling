{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(shape=(23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Dropbox\\Academics\\Master (Msc)\\MSC AI\\Sem 2\\Machine Learning\\Assignment\\Mini Project\\SubjectSentimentModelling\\basic_exploring\\testing.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Dropbox/Academics/Master%20%28Msc%29/MSC%20AI/Sem%202/Machine%20Learning/Assignment/Mini%20Project/SubjectSentimentModelling/basic_exploring/testing.ipynb#ch0000011?line=0'>1</a>\u001b[0m \u001b[39m0\u001b[39;49m \u001b[39m/\u001b[39;49m \u001b[39m0\u001b[39;49m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "0 / 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\Dropbox\\Academics\\Master (Msc)\\MSC AI\\Sem 2\\Machine Learning\\Assignment\\Mini Project\\SubjectSentimentModelling\\basic_exploring\\testing.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Dropbox/Academics/Master%20%28Msc%29/MSC%20AI/Sem%202/Machine%20Learning/Assignment/Mini%20Project/SubjectSentimentModelling/basic_exploring/testing.ipynb#ch0000004?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m StratifiedKFold\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[np.array([0,2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'DT'), ('room', 'NN'), ('is', 'VBZ'), ('too', 'RB'), ('noisy', 'JJ')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag((word_tokenize(\"This room is too noisy\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_lemmatization(text: str) -> str:\n",
    "    txt = \"\"\n",
    "    for w in word_tokenize(text):\n",
    "        txt += lemmatizer.lemmatize(w) + ' '\n",
    "    return txt.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This room is too noisy'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lemmatization(\"This room is too noisy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfdata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Dropbox\\Academics\\Master (Msc)\\MSC AI\\Sem 2\\Machine Learning\\Assignment\\Mini Project\\SubjectSentimentModelling\\basic_exploring\\testing.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 236>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Dropbox/Academics/Master%20%28Msc%29/MSC%20AI/Sem%202/Machine%20Learning/Assignment/Mini%20Project/SubjectSentimentModelling/basic_exploring/testing.ipynb#ch0000005?line=229'>230</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m numer \u001b[39m/\u001b[39m denom\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Dropbox/Academics/Master%20%28Msc%29/MSC%20AI/Sem%202/Machine%20Learning/Assignment/Mini%20Project/SubjectSentimentModelling/basic_exploring/testing.ipynb#ch0000005?line=232'>233</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_json(\u001b[39m'\u001b[39m\u001b[39m../data/Amazon_GroceryandGourmetFood.json\u001b[39m\u001b[39m'\u001b[39m, lines\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Dropbox/Academics/Master%20%28Msc%29/MSC%20AI/Sem%202/Machine%20Learning/Assignment/Mini%20Project/SubjectSentimentModelling/basic_exploring/testing.ipynb#ch0000005?line=235'>236</a>\u001b[0m dfdata\u001b[39m.\u001b[39mfillna(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Dropbox/Academics/Master%20%28Msc%29/MSC%20AI/Sem%202/Machine%20Learning/Assignment/Mini%20Project/SubjectSentimentModelling/basic_exploring/testing.ipynb#ch0000005?line=237'>238</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(dfdata[\u001b[39m'\u001b[39m\u001b[39moverall\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique()) \u001b[39m!=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Dropbox/Academics/Master%20%28Msc%29/MSC%20AI/Sem%202/Machine%20Learning/Assignment/Mini%20Project/SubjectSentimentModelling/basic_exploring/testing.ipynb#ch0000005?line=238'>239</a>\u001b[0m     dfdata[\u001b[39m'\u001b[39m\u001b[39moverallOri\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m dfdata[\u001b[39m'\u001b[39m\u001b[39moverall\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dfdata' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# general tools\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import io\n",
    "import re\n",
    "import datetime as dt\n",
    "import json\n",
    "import requests\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import statistics\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# preprocessing & utils\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# ml models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# others\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# processsing\n",
    "def pipe_cleaningText(text: str) -> str:\n",
    "    txt = text.lower()\n",
    "    return txt\n",
    "\n",
    "def pipe_removeStopWords(text: str) -> str:\n",
    "    return \" \".join([w for w in word_tokenize(text) if w not in stop_words])\n",
    "\n",
    "def pipe_lemmatization(text: str) -> str:\n",
    "    txt = \"\"\n",
    "    for w in word_tokenize(text):\n",
    "        txt += lemmatizer.lemmatize(w) + ' '\n",
    "    return txt.strip()\n",
    "\n",
    "def pipe_addPos(text: str) -> str:\n",
    "    txt = \"\"\n",
    "    for w in pos_tag(word_tokenize(text)):\n",
    "        txt += '__'.join(w) + ' '\n",
    "    return txt.strip()\n",
    "\n",
    "def pipe_normalized(text: str, bin: int) -> str:\n",
    "    txt = \"\"\n",
    "    elements = word_tokenize(text)\n",
    "    n = len(elements)\n",
    "    for i, w in enumerate(elements):\n",
    "        normVal = math.floor((i / (n - 1)) * (bin - 1)) + 1 if n != 1 else 1\n",
    "        txt += w + '__' + str(normVal) + ' '\n",
    "    return txt.strip()\n",
    "\n",
    "def pipe_subjectCleaning(text: str) -> str:\n",
    "    txt = \"\"\n",
    "    for s in sent_tokenize(text):\n",
    "        for w in pos_tag(word_tokenize(s)):\n",
    "            if w[1] != 'NNP':\n",
    "                continue\n",
    "            txt += w[0] + ' '\n",
    "    return txt.strip()\n",
    "\n",
    "# feature extraction\n",
    "def feature_tfidfUni(series: pd.Series, max_features=None) -> (sp.sparse.csr_matrix, TfidfVectorizer):\n",
    "    tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,1), max_features=max_features)\n",
    "    tfidf_vectorizer.fit(series)\n",
    "    return tfidf_vectorizer.transform(series), tfidf_vectorizer\n",
    "\n",
    "def feature_bowUni(series: pd.Series, max_features=None) -> (sp.sparse.csr_matrix, CountVectorizer):\n",
    "    bow_vectorizer = CountVectorizer(ngram_range=(1,1), max_features=max_features)\n",
    "    bow_vectorizer.fit(series)\n",
    "    return bow_vectorizer.transform(series), bow_vectorizer\n",
    "\n",
    "def feature_tfidfUniBi(series: pd.Series, max_features=None) -> (sp.sparse.csr_matrix, TfidfVectorizer):\n",
    "    tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=max_features)\n",
    "    tfidf_vectorizer.fit(series)\n",
    "    return tfidf_vectorizer.transform(series), tfidf_vectorizer\n",
    "\n",
    "def feature_bowUniBi(series: pd.Series, max_features=None) -> (sp.sparse.csr_matrix, CountVectorizer):\n",
    "    bow_vectorizer = CountVectorizer(ngram_range=(1,2), max_features=max_features)\n",
    "    bow_vectorizer.fit(series)\n",
    "    return bow_vectorizer.transform(series), bow_vectorizer\n",
    "\n",
    "# sampling\n",
    "def balancing_upsampling(data: pd.DataFrame, target: int=None) -> pd.DataFrame:\n",
    "    group_res = data.groupby(by=['overall'])['overall'].count()\n",
    "    highest_n = max(group_res.values) if not target else target\n",
    "    thedata = data[data.overall == group_res[group_res == highest_n].index[0]] if not target else data.drop(data.index)\n",
    "    for i in group_res.index:\n",
    "        if group_res.loc[i] == highest_n:\n",
    "            continue\n",
    "        tdata = data[data.overall == i]\n",
    "        sample_ind = np.random.choice(tdata.index, highest_n - group_res.loc[i], replace=True)\n",
    "        thedata = pd.concat([thedata, tdata, tdata.loc[sample_ind]])\n",
    "    return thedata\n",
    "\n",
    "def balancing_downsampling(data: pd.DataFrame, target: int=None) -> pd.DataFrame:\n",
    "    group_res = data.groupby(by=['overall'])['overall'].count()\n",
    "    lowest_n = min(group_res.values) if not target else target\n",
    "    thedata = data[data.overall == group_res[group_res == lowest_n].index[0]] if not target else data.drop(data.index)\n",
    "    for i in group_res.index:\n",
    "        if group_res.loc[i] == lowest_n:\n",
    "            continue\n",
    "        tdata = data[data.overall == i]\n",
    "        sample_ind = np.random.choice(tdata.index, lowest_n, replace=False)\n",
    "        thedata = pd.concat([thedata, tdata.loc[sample_ind]])\n",
    "    return thedata\n",
    "\n",
    "# testing\n",
    "def accuracyTrainTest(model, trainX: np.array, trainY: np.array, valX: np.array, valY: np.array, testX: np.array, testY: np.array) -> (float, float, float):\n",
    "    mod = model.fit(trainX, trainY)\n",
    "    yfit = mod.predict(trainX)\n",
    "    ypredVal = mod.predict(valX)\n",
    "    ypredTest = mod.predict(testX)\n",
    "    \n",
    "    # train result, validation result, test result\n",
    "    return accuracy_score(trainY, yfit), accuracy_score(valY, ypredVal), accuracy_score(testY, ypredTest)\n",
    "    \n",
    "def loop_testing(model, n_test: int, xArr: sp.sparse.csr_matrix, yArr: np.array, testXArr: sp.sparse.csr_matrix, testYArr: np.array) -> dict[str: list([float, float])]:\n",
    "    thedict = {}\n",
    "\n",
    "    i = 0\n",
    "    n = xArr.shape[0]\n",
    "    n_sample = math.ceil(n / n_test)\n",
    "    x_sam, y_sam = np.array([]), np.array([])\n",
    "    while i < n_test:\n",
    "        percent_sample = n_sample/xArr.shape[0]\n",
    "        if percent_sample >= 1:\n",
    "            xmain, ymain = xArr, yArr\n",
    "        else:\n",
    "            xmain, xArr, ymain, yArr = train_test_split(xArr, yArr, train_size=percent_sample, stratify=yArr, random_state=123)\n",
    "        \n",
    "        x_sam = sp.sparse.vstack((x_sam, xmain)) if x_sam.shape[0] != 0 else xmain\n",
    "        y_sam = np.hstack((y_sam, ymain)) if y_sam.shape[0] != 0 else ymain\n",
    "        xtrain, xtest, ytrain, ytest = train_test_split(x_sam, y_sam, train_size=0.9, stratify=y_sam, random_state=123)\n",
    "\n",
    "        resTrain, resVal, resTest = accuracyTrainTest(model, xtrain, ytrain, xtest, ytest, testXArr, testYArr)\n",
    "        thedict[x_sam.shape[0]] = [resTrain, resVal, resTest]\n",
    "\n",
    "        i += 1\n",
    "    return thedict\n",
    "\n",
    "# visualization\n",
    "def show_result(ypred: np.array, ytarget: np.array) -> None:\n",
    "    label = ['Positive', 'Neutral', 'Negative']\n",
    "    report = classification_report(ypred, ytarget, labels=label)\n",
    "    conf_matrix = confusion_matrix(ypred, ytarget, labels=label)\n",
    "\n",
    "    group_names = ['True Pos', 'False Neu', 'False Neg',\n",
    "                   'False Pos', 'True Neu', 'False Neg',\n",
    "                   'False Pos', 'False Neu', 'True Neg']\n",
    "    group_percentages = ['{0:.2%}'.format(value) for value in conf_matrix.flatten() / np.sum(conf_matrix)]\n",
    "    labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in zip(group_names, group_percentages, conf_matrix.flatten())]\n",
    "    labels = np.asarray(labels).reshape(3, 3)\n",
    "\n",
    "    df_cm = pd.DataFrame(data=conf_matrix, index=label, columns=label)\n",
    "\n",
    "    print(report)\n",
    "    fix, axe = plt.subplots(figsize=(15, 8), nrows=1, ncols=1)\n",
    "    sns.heatmap(df_cm, xticklabels=label, yticklabels=label, annot=labels, ax=axe, cmap = 'Blues', fmt = '')\n",
    "    plt.show();\n",
    "\n",
    "def visualized_loopTesting(result_loopTesting: dict[str: list([float, float])]) -> None:\n",
    "    train_res, val_res, test_res = dict(), dict(), dict()\n",
    "    for res in result_loopTesting:\n",
    "        train_res[res] = result[res][0]\n",
    "        val_res[res] = result[res][1]\n",
    "        test_res[res] = result[res][2]\n",
    "\n",
    "    fig, axe = plt.subplots(figsize=(15, 8), nrows=1, ncols=1)\n",
    "    sns.lineplot(y=train_res.values(), x=train_res.keys() , ax=axe, label='train-result')\n",
    "    sns.lineplot(y=val_res.values(), x=val_res.keys(), ax=axe, label='val-result')\n",
    "    sns.lineplot(y=test_res.values(), x=test_res.keys(), ax=axe, label='test-result')\n",
    "    axe.set_title(\"Highest Score: {}\".format(max(test_res.values())))\n",
    "    axe.set_xlabel(\"Dataset Size\")\n",
    "    axe.set_ylabel(\"Accuracy\")\n",
    "    axe.set_ylim([0.65, 1.0])\n",
    "    axe.xaxis.set_major_formatter(FormatStrFormatter('%.0f'))\n",
    "    plt.show();\n",
    "\n",
    "# others\n",
    "def correlation(x: list, y: list) -> float:\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    bar_x = x.mean()\n",
    "    bar_y = y.mean()\n",
    "    sum_xixbar_yiybar = sum((x - bar_x) * (y - bar_y))\n",
    "    sum_xixbar2 = sum((x - bar_x) ** 2)\n",
    "    sum_yiybar2 = sum((y - bar_y) ** 2)\n",
    "\n",
    "    numer = sum_xixbar_yiybar\n",
    "    denom = (sum_xixbar2 * sum_yiybar2) ** (1 / 2)\n",
    "\n",
    "    r = numer / denom if denom != 0 else 0\n",
    "\n",
    "    return r\n",
    "\n",
    "def gradient(x: list, y: list) -> float:\n",
    "    p1 = [x[0], y[0]]\n",
    "    p2 = [x[2], y[2]]\n",
    "\n",
    "    numer = p1[1] - p2[1]\n",
    "    denom = p1[0] - p2[0]\n",
    "\n",
    "    return numer / denom\n",
    "    \n",
    "\n",
    "df = pd.read_json('../data/Amazon_GroceryandGourmetFood.json', lines=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdata = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdata.fillna(\"\", inplace=True)\n",
    "\n",
    "if len(dfdata['overall'].unique()) != 3:\n",
    "    dfdata['overallOri'] = dfdata['overall']\n",
    "dfdata['overall'] = dfdata['overallOri'].apply(lambda x: \"Positive\" if x > 3 else \"Negative\" if x < 3 else \"Neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_n = 500 * 1000\n",
    "dfdataMain, _ = train_test_split(dfdata, train_size=target_n / dfdata.shape[0], stratify=dfdata['overall'], random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training & testing\n",
    "target_n = 450 * 1000\n",
    "dfdataTrain, dfdataTest = train_test_split(dfdataMain, train_size=target_n / dfdataMain.shape[0], stratify=dfdataMain['overall'], random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for validation\n",
    "target_n = 45 * 1000\n",
    "dfdataValid, dfdataTrainSub = train_test_split(dfdataTrain, train_size=target_n / dfdataTrain.shape[0], stratify=dfdataTrain['overall'], random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for validation training & testing\n",
    "target_n = 40 * 1000\n",
    "dfdataValidTrain, dfdataValidTest = train_test_split(dfdataValid, train_size=target_n / dfdataValid.shape[0], stratify=dfdataValid['overall'], random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsampling minority group for validation training\n",
    "if statistics.variance(dfdataValidTrain.groupby(by=['overall'])['overall'].count().values) >= 10 * 1000:\n",
    "    dfdataValidTrain = balancing_upsampling(dfdataValidTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(txt: str) -> str:\n",
    "    txt = pipe_cleaningText(txt)\n",
    "    txt = pipe_lemmatization(txt)\n",
    "    txt = pipe_normalized(txt, 5)\n",
    "    return txt\n",
    "    \n",
    "tdf1 = dfdataValidTrain.copy()\n",
    "tdf2 = dfdataValidTest.copy()\n",
    "tdf1['reviewText'] = tdf1['reviewText'].apply(lambda x: pipeline(x))\n",
    "tdf2['reviewText'] = tdf2['reviewText'].apply(lambda x: pipeline(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xArr, featureModel = feature_bowUniBi(tdf1['reviewText'], 150000)\n",
    "yArr = tdf1['overall'].to_numpy()\n",
    "testXArr, testYArr = featureModel.transform(tdf2['reviewText']), tdf2['overall'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 4: mlp\n",
    "\n",
    "mlp_model = MLPClassifier()\n",
    "result = loop_testing(mlp_model, 10, xArr, yArr, testXArr, testYArr)\n",
    "print(\"Correlation last 3: {:.4f}\".format(correlation(list(result.keys())[-3:], [x[2] for x in result.values()][-3:])))\n",
    "print(\"Gradient last 3: {:.4f}\".format(gradient(range(1, 4), [x[2] for x in result.values()][-3:])))\n",
    "visualized_loopTesting(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dropbox\\Academics\\Master (Msc)\\MSC AI\\Sem 2\\Machine Learning\\Assignment\\Mini Project\\SubjectSentimentModelling\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3398: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/Amazon_Electronics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>07 17, 2002</td>\n",
       "      <td>A1N070NS9CJQ2I</td>\n",
       "      <td>0060009810</td>\n",
       "      <td>{'Format:': ' Hardcover'}</td>\n",
       "      <td>Teri Adams</td>\n",
       "      <td>This was the first time I read Garcia-Aguilera...</td>\n",
       "      <td>Hit The Spot!</td>\n",
       "      <td>1026864000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>07 6, 2002</td>\n",
       "      <td>A3P0KRKOBQK1KN</td>\n",
       "      <td>0060009810</td>\n",
       "      <td>{'Format:': ' Hardcover'}</td>\n",
       "      <td>Willa C.</td>\n",
       "      <td>As with all of Ms. Garcia-Aguilera's books, I ...</td>\n",
       "      <td>one hot summer is HOT HOT HOT!</td>\n",
       "      <td>1025913600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>07 3, 2002</td>\n",
       "      <td>A192HO2ICJ75VU</td>\n",
       "      <td>0060009810</td>\n",
       "      <td>{'Format:': ' Hardcover'}</td>\n",
       "      <td>Kit</td>\n",
       "      <td>I've not read any of Ms Aguilera's works befor...</td>\n",
       "      <td>One Hot Summer</td>\n",
       "      <td>1025654400</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>06 30, 2002</td>\n",
       "      <td>A2T278FKFL3BLT</td>\n",
       "      <td>0060009810</td>\n",
       "      <td>{'Format:': ' Hardcover'}</td>\n",
       "      <td>Andres</td>\n",
       "      <td>This romance novel is right up there with the ...</td>\n",
       "      <td>I love this book!</td>\n",
       "      <td>1025395200</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>06 28, 2002</td>\n",
       "      <td>A2ZUXVTW8RXBXW</td>\n",
       "      <td>0060009810</td>\n",
       "      <td>{'Format:': ' Hardcover'}</td>\n",
       "      <td>John</td>\n",
       "      <td>Carolina Garcia Aguilera has done it again.  S...</td>\n",
       "      <td>One Hot Book</td>\n",
       "      <td>1025222400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0        5      True  07 17, 2002  A1N070NS9CJQ2I  0060009810   \n",
       "1        5     False   07 6, 2002  A3P0KRKOBQK1KN  0060009810   \n",
       "2        5     False   07 3, 2002  A192HO2ICJ75VU  0060009810   \n",
       "3        4     False  06 30, 2002  A2T278FKFL3BLT  0060009810   \n",
       "4        5     False  06 28, 2002  A2ZUXVTW8RXBXW  0060009810   \n",
       "\n",
       "                       style reviewerName  \\\n",
       "0  {'Format:': ' Hardcover'}   Teri Adams   \n",
       "1  {'Format:': ' Hardcover'}     Willa C.   \n",
       "2  {'Format:': ' Hardcover'}          Kit   \n",
       "3  {'Format:': ' Hardcover'}       Andres   \n",
       "4  {'Format:': ' Hardcover'}         John   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  This was the first time I read Garcia-Aguilera...   \n",
       "1  As with all of Ms. Garcia-Aguilera's books, I ...   \n",
       "2  I've not read any of Ms Aguilera's works befor...   \n",
       "3  This romance novel is right up there with the ...   \n",
       "4  Carolina Garcia Aguilera has done it again.  S...   \n",
       "\n",
       "                          summary  unixReviewTime vote image  \n",
       "0                   Hit The Spot!      1026864000  NaN   NaN  \n",
       "1  one hot summer is HOT HOT HOT!      1025913600  NaN   NaN  \n",
       "2                  One Hot Summer      1025654400    2   NaN  \n",
       "3               I love this book!      1025395200    3   NaN  \n",
       "4                    One Hot Book      1025222400  NaN   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20941539"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall\n",
       "1     2409983\n",
       "2     1136973\n",
       "3     1526548\n",
       "4     3298596\n",
       "5    12569439\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by=['overall']).overall.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall\n",
       "1    1.0\n",
       "2    2.0\n",
       "3    3.0\n",
       "4    4.0\n",
       "5    5.0\n",
       "Name: overall, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by=['overall']).overall.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20941534</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>04 29, 2017</td>\n",
       "      <td>A1RH0C7YHWZQER</td>\n",
       "      <td>B01HJF704M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Randy Garmire</td>\n",
       "      <td>Had it 1 day and it quit working, will be retu...</td>\n",
       "      <td>JUNK</td>\n",
       "      <td>1493424000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20941535</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>04 17, 2017</td>\n",
       "      <td>A2955VBJEJZ4S</td>\n",
       "      <td>B01HJF704M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BJN</td>\n",
       "      <td>Received item in 2 days. Product worked as adv...</td>\n",
       "      <td>Instructions easy and clear</td>\n",
       "      <td>1492387200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20941536</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>03 31, 2017</td>\n",
       "      <td>A1FGCIRPRNZWD5</td>\n",
       "      <td>B01HJF704M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brando</td>\n",
       "      <td>I have it plugged into a usb extension on my g...</td>\n",
       "      <td>Works well enough..</td>\n",
       "      <td>1490918400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20941537</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>02 16, 2017</td>\n",
       "      <td>AOEG7L8HI8DXJ</td>\n",
       "      <td>B01HJF704M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mack</td>\n",
       "      <td>Fast delivery product was simple to use</td>\n",
       "      <td>Good product</td>\n",
       "      <td>1487203200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20941538</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>02 11, 2017</td>\n",
       "      <td>A1BXCUK9AT7KWG</td>\n",
       "      <td>B01HJF704M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clancy</td>\n",
       "      <td>Working as advertised, so far no problems.</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1486771200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          overall  verified   reviewTime      reviewerID        asin style  \\\n",
       "20941534        1      True  04 29, 2017  A1RH0C7YHWZQER  B01HJF704M   NaN   \n",
       "20941535        5      True  04 17, 2017   A2955VBJEJZ4S  B01HJF704M   NaN   \n",
       "20941536        5      True  03 31, 2017  A1FGCIRPRNZWD5  B01HJF704M   NaN   \n",
       "20941537        5      True  02 16, 2017   AOEG7L8HI8DXJ  B01HJF704M   NaN   \n",
       "20941538        5      True  02 11, 2017  A1BXCUK9AT7KWG  B01HJF704M   NaN   \n",
       "\n",
       "           reviewerName                                         reviewText  \\\n",
       "20941534  Randy Garmire  Had it 1 day and it quit working, will be retu...   \n",
       "20941535            BJN  Received item in 2 days. Product worked as adv...   \n",
       "20941536         Brando  I have it plugged into a usb extension on my g...   \n",
       "20941537           Mack            Fast delivery product was simple to use   \n",
       "20941538         Clancy         Working as advertised, so far no problems.   \n",
       "\n",
       "                              summary  unixReviewTime vote image  \n",
       "20941534                         JUNK      1493424000  NaN   NaN  \n",
       "20941535  Instructions easy and clear      1492387200  NaN   NaN  \n",
       "20941536          Works well enough..      1490918400  NaN   NaN  \n",
       "20941537                 Good product      1487203200  NaN   NaN  \n",
       "20941538                   Five Stars      1486771200  NaN   NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall                  0\n",
       "verified                 0\n",
       "reviewTime               0\n",
       "reviewerID               0\n",
       "asin                     0\n",
       "style             10476370\n",
       "reviewerName          2668\n",
       "reviewText            9670\n",
       "summary               4896\n",
       "unixReviewTime           0\n",
       "vote              18254610\n",
       "image             20594419\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           139\n",
       "1            42\n",
       "2            51\n",
       "3           105\n",
       "4            45\n",
       "           ... \n",
       "20941534     11\n",
       "20941535     13\n",
       "20941536     75\n",
       "20941537      7\n",
       "20941538      7\n",
       "Name: reviewText, Length: 20931869, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[~df.reviewText.isnull()]['reviewText'].apply(lambda x: len(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"', '\"abcd\"']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(['\"' + 'abcd' + '\"'for _ in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "','.join([str(1) for _ in range(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcd'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(['abcd' for a in range(500)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, 0, 1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[-1] + [x for x in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2,-9,-1,-5,10,0,8,10,1,-9]\n",
      "[1,3,3,10,7,-10,-7,-4,-1,-3]\n",
      "[-1,8,-6,-3,4,-10,-6,-6,-2,1]\n",
      "[2,-2,2,4,-4,5,6,-2,-6,2]\n",
      "[4,2,6,-10,7,-9,5,-10,-5,-6]\n",
      "[1,10,1,-4,-7,6,0,7,-8,-2]\n",
      "[3,10,7,5,-5,-5,6,-6,1,-8]\n",
      "[-3,10,-3,-2,-2,-9,1,-9,4,6]\n",
      "[-7,8,-9,-7,-2,-2,-6,-10,8,-2]\n",
      "[-2,-8,10,6,-1,-1,5,-4,9,-7]\n",
      "[6,1,4,5,-7,9,8,-3,-1,-3]\n",
      "[-5,-10,9,-9,-3,8,-4,-8,-10,2]\n",
      "[7,-2,-9,-9,-6,9,-3,-3,1,-10]\n",
      "[5,5,2,8,-1,-7,-6,5,-6,-4]\n",
      "[-7,-10,6,-2,2,-5,-1,-2,10,2]\n",
      "[-2,-1,8,-5,-7,0,5,-8,-5,10]\n",
      "[-9,-9,4,-6,-6,7,4,-3,-10,-5]\n",
      "[8,7,-1,9,-7,-5,-2,9,-1,7]\n",
      "[6,6,9,7,-5,2,-4,-6,5,-4]\n",
      "[1,-7,4,-8,-2,6,-2,-6,10,9]\n",
      "[-5,-5,7,6,6,7,-3,2,-9,5]\n",
      "[-1,4,-5,-8,0,-5,-5,-6,-10,-2]\n",
      "[-9,-3,9,0,3,7,-4,9,-9,-9]\n",
      "[-10,7,8,4,-7,-10,0,10,-4,-5]\n",
      "[-3,4,5,9,-4,-2,2,5,5,6]\n",
      "[-8,6,10,1,-9,6,-3,-2,9,6]\n",
      "[-1,1,-8,-2,-2,-10,-7,8,-4,8]\n",
      "[1,9,-1,-4,1,-2,3,-10,9,-6]\n",
      "[-8,8,-7,7,-1,3,5,2,-8,6]\n",
      "[8,-1,-4,8,-6,-1,0,-6,8,2]\n",
      "[4,9,-8,5,-5,0,-5,9,10,-9]\n",
      "[5,-1,-7,7,6,-6,-6,9,-9,-4]\n",
      "[-8,2,2,9,6,5,-4,-6,-2,-10]\n",
      "[-5,-8,-4,1,3,-7,6,-9,3,7]\n",
      "[-7,10,-9,-3,0,5,-2,-5,3,7]\n",
      "[-6,-6,-8,6,3,-1,4,-1,-9,3]\n",
      "[-7,5,3,-3,-8,9,6,8,3,-3]\n",
      "[0,2,-5,4,6,3,-10,10,9,10]\n",
      "[2,-5,-10,4,3,-3,-2,-4,2,10]\n",
      "[-4,-10,-8,4,6,0,-10,-6,-9,9]\n",
      "[5,-10,4,4,-10,5,-10,-9,2,8]\n",
      "[-2,-5,-8,-9,1,1,-2,-2,-7,4]\n",
      "[1,-1,10,-5,-1,-4,-1,6,-1,10]\n",
      "[-4,-3,-10,1,-5,0,10,-8,10,-7]\n",
      "[-4,-8,10,-8,-10,-7,7,6,0,2]\n",
      "[5,-8,-2,7,-2,-8,-6,7,4,3]\n",
      "[6,3,1,3,-2,-6,-5,8,-6,1]\n",
      "[10,-10,7,4,-1,-7,9,-6,7,-5]\n",
      "[1,5,-4,-2,-4,0,-5,-4,-2,6]\n",
      "[-4,4,3,3,-9,3,9,4,0,1]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(50):\n",
    "    print('[' + ','.join([str(random.randint(-10, 10)) for _ in range(10)]) + ']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0b10111'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "101 -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4 >> 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10 -> 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 << 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11111111111111111111111111111101'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format(4294967293, 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'54,298,465,243,216,92,136,124,434,223,304,219,249,232,165,276,344,136,12,229,183,158,482,196,138,264,404,377,80,335,207,415,173,65,165,319,334,52,427,354,256,112,63,480,458,370,342,191,485,63,289,264,126,202,61,248,474,491,365,455,290,158,450,339,268,304,323,122,262,67,137,417,484,268,422,367,72,379,10,491,161,326,86,303,27,355,425,201,450,124,134,356,246,218,402,341,416,475,356,477,38,316,5,135,149,481,215,73,394,6,492,368,135,331,295,100,93,200,496,80,21,84,114,379,261,440,236,14,59,143,261,90,181,195,36,31,81,318,347,497,233,374,240,91,189,11,406,310,319,18,301,164,316,403,400,56,130,209,1,109,154,152,100,122,100,230,355,237,408,485,3,338,230,460,411,395,361,385,82,443,17,486,40,221,210,171,418,422,425,221,238,335,72,323,365,496,114,270,220,238,179,383,195,208,12,31,83,189,184,373,329,404,442,482,65,92,130,17,379,403,17,137,178,85,307,282,254,442,82,385,217,254,39,482,323,233,431,69,456,82,474,283,260,374,493,496,367,481,33,184,347,197,173,122,43,430,13,222,251,211,20,51,384,98,233,370,374,284,45,228,94,111,170,453,248,486,208,177,95,297,72,107,390,38,17,237,300,66,330,295,481,373,377,225,86,275,285,456,275,197,253,344,46,471,317,120,221,108,45,469,218,43,180,313,170,81,242,390,344,139,351,111,212,10,6,455,433,461,138,342,268,356,117,393,283,241,290,378,272,223,209,384,460,195,103,90,47,212,414,210,223,301,190,70,485,338,367,142,312,113,146,53,25,119,65,489,3,55,366,341,82,253,86,12,83,195,484,499,373,483,206,222,315,320,137,271,79,297,343,97,103,213,191,250,431,144,193,178,481,15,362,136,187,273,191,499,37,189,102,377,480,399,322,298,365,356,190,84,162,448,495,252,156,212,57,195,382,297,8,40,29,261,316,80,110,173,221,451,358,488,57,72,409,105,152,409,231,136,40,63,351,474,254,254,31,300,311,21,312,215,93,82,1,103,315,19,56,277,241,398,96,91,187,431,361,325,455,173,133,154,369,364,356,402,177,225,126,460,278,377,22,373,195,407,85,124,195,388,214,447,157,268,463,188,327,371,251,147,454,88,308,121,108,419,366,78,487,331,286,251,183,484,147,341,427,102,267,378,443,53,368,487,212,264,321,14,9,216,344,135,145,328,481,475,109,122,381,202,288,171,176,175,43,469,469,129,116,54,422,64,467,292,297,346,404,354,366,387,56,28,142,468,9,115,204,199,424,294,165,116,137,167,48,218,292,283,88,239,79,389,100,1,238,30,209,175,72,179,13,282,70,500,55,216,402,11,84,284,215,135,422,314,363,17,130,286,494,330,136,278,81,484,57,15,108,195,211,260,178,410,368,126,153,442,284,275,82,425,402,64,469,81,344,396,489,68,489,133,243,12,243,27,318,54,499,111,345,121,257,418,382,340,270,314,211,279,451,191,224,307,365,337,170,229,429,460,349,291,32,323,277,495,207,304,89,412,474,40,199,112,148,346,7,401,457,306,412,98,89,256,486,195,252,313,48,385,171,313,54,475,380,350,351,424,254,424,277,27,167,450,13,103,6,198,41,177,25,82,307,189,106,351,186,51,141,423,50,11,342,28,300,418,153,4,252,449,48,333,379,42,124,104,71,47,125,96,432,103,193,407,457,174,308,246,285,14,284,87,70,143,492,224,193,196,75,220,394,459,426,217,146,106,359,377,60,443,413,298,425,323,365,376,340,102,166,182,168,45,69,59,237,129,264,65,237,286,303,96,414,206,341,134,68,101,426,218,236,332,213,366,353,281,417,224,191,170,46,308,252,12,196,117,313,106,292,182,464,146,372,78,478,53,491,424,319,149,13,35,237,498,364,456,307,270,204,282,306,324,407,408,118,250,499,476,129,220,303,129,282,327,367,51,435,126,419,271,447,355,220,357,58,362,428,263,87,146,415,88,216,156,244,465,231,105,310,331,93,334,176,431,441,129,77,164,91,405,335,123,414,218,485,106,372,355,355,3,446,143,279,456,219,167,454,159,181,74,92,387,48,43,16,194,110,214,348,496,177,10,302,56,478,28,13,243,158,402,268,245,53,477,439,448,418,352,118,404,242,404,286,449,245,287,284,270,416,44,423,479,404,147,412,322,139,198,158,230,254,201,104,225,18,462,301,34,46,291,206,427,245,359,456,212,177,274,218,255,90,352,349,276,47,419,223,476,291,481,455,405,482,381,280,225,473,179,330,71,488,359,99,71,255,355,402,418,339,32,425,156,191,316,109,436,49,348,247,117,349,155,126,428,391,354,499,464,25,82,215,192,326,75,290,197,144,134,494,261,88,137,496,47,332,490,400,448,295,212,369,65,317,304,105,228,270,146,31,147,141,103,282,228,131,356,206,346,226,223,411,4,328,66,227,281,180,21,24,63,482,355,166,395,168,70,31,492,191,361,349,116,356,286,33,168,433,287,108,466,141,361,93,278,301,235,167,280,255,496,150,62,1,371,71,107,283,45,426,347,254,268,181,324,476,400,251,428,183,427,409,384,393,223,306,55,358,293,464,330,330,125,312,188,333,29,498,247,133,99,220,21,67,44,329,208,500,270,35,180,119,500,429,165,108,144,300,101,238,204,482,207,482,148,486,230,479,78,431,283,94,124,321,382,90,399,85,343,263,44,85,445,264,25,192,250,433,161,425,456,109,230,330,152,92,223,326,126,477,418,237,489,230,28,164,40,21,369,362,43,195,104,388,408,381,388,426,346,137,411,227,413,139,489,192,133,408,351,57,16,170,227,7,303,444,459,155,236,489,39,467,2,26,8,346,376,186,114,316,415,303,30,22,405,86,318,17,334,479,135,308,340,223,191,213,203,416,83,276,146,192,382,72,327,130,141,328,190,30,68,221,69,405,128,128,331,40,170,425,244,166,163,279,212,91,310,280,84,103,201,211,283,74,160,172,205,277,486,443,245,139,465,447,48,466,222,107,160,291,374,2,255,407,385,47,300,15,7,248,398,243,393,162,341,285,362,2,244,452,259,320,317,107,252,283,217,321,370,110,488,238,437,61,128,334,320,414,473,237,146,224,441,298,337,82,57,27,53,6,193,163,421,248,210,83,181,24,9,10,316,367,424,20,498,16,198,397,495,4,296,306,274,83,97,343,324,278,163,231,486,428,416,422,497,304,247,104,105,447,122,278,212,224,275,382,393,118,202,96,4,199,339,246,211,282,37,408,184,148,305,474,342,9,345,370,131,260,65,357,66,119,302,481,445,434,19,430,259,103,12,483,496,330,44,209,183,187,254,69,312,383,82,70,112,413,207,213,297,132,201,201,126,406,195,26,253,415,293,430,58,396,72,221,154,112,59,383,166,493,243,24,303,52,284,203,124,76,173,478,280,217,5,299,188,497,27,289,367,497,439,28,211,355,63,444,168,123,170,155,314,88,323,254,130,92,215,98,137,219,243,467,284,408,32,420,390,255,353,277,104,346,254,174,267,70,243,9,97,362,461,26,258,55,164,250,341,204,414,487,261,499,7,453,80,268,374,439,253,90,73,183,256,53,100,176,109,333,1,307,107,155,499,462,346,485,295,326,416,245,337,416,222,459,221,158,164,81,134,416,52,394,70,483,308,439,335,334,358,157,24,306,321,110,36,87,173,278,396,58,437,50,498,130,344,1,343,325,341,357,429,409,129,73,492,384,18,206,54,342,194,344,365,16,284,376,240,348,233,322,40,6,486,345,487,419,489,428,433,34,372,359,482,145,206,428,317,101,127,296,107,413,70,301,235,66,98,367,282,431,214,203,461,434,439,300,441,437,405,85,236,467,433,218,156,7,359,161,460,41,23,87,420,148,399,252,92,394,431,140,317,138,114,194,385,422,117,251,377,288,401,148,356,219,314,6,26,39,101,403,188,261,76,78,173,5,381,323,271,496,304,25,244,35,387,157,162,191,49,283,381,467,224,245,51,165,61,166,448,186,213,157,40,204,325,135,206,108,294,345,348,468,334,28,276,413,247,435,176,22,72,407,39,475,406,159,360,15,316,234,306,111,272,477,289,402,340,387,153,410,415,298,364,327,409,450,201,346,169,189,68,43,212,131,498,292,176,33,361,277,378,87,206,148,300,341,74,328,162,155,36,472,346,132,494,314,318,127,12,182,482,464,93,489,249,373,298,302,255,55,336,56,484,450,205,283,137,212,95,342,429,213,106,462,357,49,83,381,180,303,251,136,437,328,175,177,212,428,188,31,123,290,155,173,375,393,460,407,467,113,201,78,16,167,170,476,163,468,397,224,311,93,231,83,39,42,223,313,266,328,425,40,100,371,260,488,237,114,53,494,166,236,143,36,479,453,370,126,67,380,410,496,300,107,265,360,489,342,90,187,377,475,318,113,329,86,41,165,288,329,277,374,129,207,184,422,347,321,36,430,125,352,191,5,287,112,40,189,351,232,479,433,56,386,400,462,148,287,382,436,360,375,83,20,433,479,112,492,380,265,366,50,418,205,296,76,33,199,262,472,470,298,160,500,333,419,394,17,223,408,282,47,14,318,142,131,165,346,261,396,177,388,389,105,246,183,191,467,167,18,452,278,299,337,298,442,429,453,367,314,298,20,279,177,44,351,28,326,181,93,342,124,363,203,326,28,483,245,460,270,351,289,11,262,394,204,93,126,393,433,139,488,62,103,400,411,482,195,358,435,453,363,12,270,165,459,492,408,186,422,76,442,256,52,84,416,478,490,19,458,101,301,438,429,72,270,457,483,277,37,89,307,248,98,100,334,344,282,214,486,437,57,407,32,164,480,287,180,183,82,228,393,171,347,488,208,390,344,82,449,127,74,51,1,483,104,188,182,135,222,153,432,34,313,497,156,73,97,146,95,327,17,494,282,443,362,331,355,197,299,175,485,483,236,465,302,431,241,282,489,420,55,236,305,220,246,347,298,20,450,57,478,51,38,251,296,443,119,321,92,123,438,113,365,119,52,362,23,105,105,26,236,193,63,149,307,407,495,81,341,195,32,116,41,226,11,171,186,65,137,393,444,254,463,375,77,461,118,173,111,113,45,290,289,417,171,247,426,476,304,235,439,151,91,202,204,282,409,332,426,1,45,305,383,346,462,342,424,7,280,222,172,366,373,175,264,159,199,8,93,495,43,330,174,205,125,156,300,396,184,73,46,226,417,354,478,30,230,384,218,367,105,72,89,277,77,245,434,68,96,64,379,157,459,391,434,164,312,150,106,459,91,89,496,353,110,25,98,181,243,84,137,35,212,12,134,410,77,263,105,434,263,333,450,368,157,257,464,420,257,414,152,380,420,377,490,283,257,31,7,175,69,297,389,171,116,487,30,336,11,124,148,299,216,222,99,228,137,285,35,184,392,489,201,166,60,28,312,92,192,440,3,196,228,76,228,337,98,367,443,368,381,72,367,41,131,286,243,13,267,462,80,443,212,345,353,22,212,295,295,91,454,60,158,163,85,12,476,212,88,406,94,114,374,142,463,397,258,488,226,487,99,122,386,209,478,492,469,472,280,27,272,369,404,494,236,118,158,185,396,405,245,215,380,394,189,388,228,66,125,489,291,339,76,349,293,109,262,383,135,313,363,145,334,384,76,32,439,196,467,101,225,235,415,400,78,57,300,158,184,115,168,271,485,225,359,246,130,218,114,435,60,102,307,129,155,135,419,253,86,104,64,191,369,374,296,117,356,456,331,220,238,474,230,297,82,150,110,205,304,312,177,425,232,294,422,195,489,105,72,487,96,260,334,197,127,340,468,201,406,106,144,75,180,278,337,234,362,148,316,320,310,163,315,475,264,255,361,427,209,434,492,359,12,393,177,198,85,93,107,172,223,368,455,175,74,27,178,250,337,300,314,414,94,491,357,292,236,113,90,162,257,173,298,460,289,32,499,148,231,472,488,423,47,327,424,441,116,399,449,258,285,286,128,164,177,317,342,122,30,137,472,462,92,420,407,123,260,229,434,335,2,454,67,71,144,129,393,382,279,110,426,377,225,146,145,374,337,129,491,32,473,306,446,243,196,104,391,151,192,472,286,430,15,212,471,95,410,113,415,212,137,78,11,432,180,244,324,124,420,205,167,450,256,385,496,443,13,354,466,253,415,20,369,68,471,333,376,492,339,151,437,84,178,154,162,160,372,443,106,183,125,325,493,306,292,356,396,144,85,423,284,438,182,422,362,266,124,12,327,267,160,176,299,409,214,440,14,463,214,482,348,201,458,281,143,96,326,481,403,452,172,343,104,27,65,51,143,25,190,423,40,449,315,337,129,429,288,7,429,13,463,182,387,121,376,259,17,437,355,317,338,291,40,423,480,316,63,495,17,101,317,270,201,470,395,294,137,231,170,100,109,259,298,92,401,134,327,422,481,24,252,2,252,174,179,389,46,435,331,239,327,438,407,51,352,362,481,295,345,494,250,285,229,422,337,467,464,39,311,478,68,193,253,379,300,18,351,69,276,18,433,465,493,376,408,428,116,57,288,37,71,392,373,278,404,488,192,36,379,493,286,93,17,184,174,82,375,294,341,151,286,190,320,29,366,4,389,230,263,109,30,299,366,288,108,150,436,473,134,427,458,116,192,360,283,229,74,389,212,342,111,145,488,377,364,200,188,110,206,245,259,235,223,117,494,398,437,299,9,449,429,363,177,256,340,486,279,292,301,300,378,246,404,180,52,440,252,432,433,334,15,188,295,431,344,351,176,77,201,6,397,471,444,181,108,473,319,212,183,249,94,33,277,94,31,226,274,307,211,195,390,318,155,251,398,204,213,101,91,69,107,244,330,180,355,370,444,11,112,229,154,478,363,196,22,159,371,366,411,406,155,219,439,175,396,133,50,52,445,396,48,98,140,385,463,470,306,115,321,107,275,25,484,288,440,484,12,27,133,198,85,211,445,244,284,112,190,184,171,390,3,81,369,29,481,404,115,14,52,363,390,204,291,127,151,153,282,93,360,43,275,258,141,206,449,327,359,102,391,21,428,73,264,308,58,385,73,380,116,359,109,195,441,65,394,72,500,253,27,375,20,287,444,493,103,301,238,288,382,132,4,167,116,286,133,281,308,87,78,227,43,364,23,317,454,305,142,383,490,63,157,500,388,398,30,329,29,459,359,329,46,139,24,178,374,368,271,126,153,154,29,376,477,90,254,151,213,491,105,466,281,112,152,76,482,408,156,63,232,408,42,156,124,61,24,439,311,454,262,382,325,113,184,30,496,306,387,368,154,318,209,171,158,9,7,247,161,83,349,412,218,32,264,131,109,316,209,149,45,405,42,53,377,199,349,237,170,200,267,285,369,436,371,41,306,69,252,169,431,260,162,189,27,483,392,480,424,47,183,423,376,103,316,221,373,475,247,264,129,396,119,450,163,68,6,428,179,399,202,84,105,235,198,25,178,334,426,167,42,367,438,111,271,483,161,8,69,113,166,114,442,80,194,57,208,99,58,125,225,182,481,237,309,375,197,96,424,333,206,34,95,326,353,64,366,496,347,393,225,477,95,315,229,494,122,447,427,69,485,121,80,208,228,251,413,351,248,54,22,225,151,147,233,152,11,377,261,88,39,281,458,143,467,307,96,400,100,210,290,376,445,163,201,211,467,423,433,61,74,355,331,497,270,119,215,34,366,437,253,314,41,317,256,284,127,249,275,166,431,6,226,342,261,452,128,89,328,343,187,172,18,222,305,366,500,495,121,289,56,327,55,289,150,129,377,298,443,2,356,428,352,252,311,321,288,102,43,88,192,155,357,233,364,37,452,206,421,309,418,74,104,183,224,449,151,342,348,463,281,18,176,369,448,454,202,6,188,221,429,111,282,177,116,405,445,157,249,446,148,98,351,21,464,368,143,393,261,233,15,431,377,266,382,10,356,470,21,172,263,258,251,447,481,99,327,394,68,475,466,265,297,476,439,72,444,37,87,215,70,254,96,32,9,362,35,281,291,471,303,499,420,179,141,430,271,209,124,59,257,99,278,422,152,488,374,263,107,225,374,270,117,358,224,442,469,145,450,73,23,408,299,295,380,184,312,368,487,130,175,19,46,143,115,318,443,403,320,310,223,87,378,198,286,57,14,248,15,167,218,222,78,411,424,128,360,473,403,142,49,389,76,61,392,75,3,337,26,223,193,225,308,230,422,323,251,90,121,434,200,291,398,159,308,472,88,239,173,293,414,65,23,237,254,86,15,4,488,435,36,14,211,157,364,213,382,167,166,241,499,152,114,500,71,174,393,317,70,89,209,223,195,209,365,396,75,422,138,126,379,481,434,80,30,133,420,364,442,270,137,366,329,167,131,254,445,345,412,63,403,192,490,145,192,346,499,65,290,421,393,197,83,28,208,76,39,225,319,367,113,438,154,4,387,6,312,474,38,198,367,377,147,202,71,300,451,1,228,377,194,459,54,190,366,13,242,429,49,356,80,446,138,485,85,242,80,389,381,498,452,343,234,209,325,61,384,214,304,397,200,125,282,151,371,14,377,26,47,497,390,383,64,8,333,267,157,90,43,171,53,318,123,105,453,400,191,352,289,220,128,207,496,332,316,70,386,36,173,372,69,453,87,475,42,67,230,430,413,349,429,436,20,338,261,224,28,216,32,290,210,85,276,297,18,288,190,466,281,103,73,281,103,378,169,92,129,203,312,304,252,17,267,139,495,388,353,209,422,448,342,482,459,214,251,339,54,64,57,100,83,304,238,362,118,482,297,272,171,453,322,225,74,30,267,320,290,397,40,41,122,247,208,52,409,251,4,12,125,459,67,251,346,397,177,76,345,474,27,120,483,61,242,327,384,360,139,196,262,147,420,19,60,135,140,272,332,410,466,323,235,88,96,157,191,495,80,476,311,73,136,58,12,377,419,261,344,311,278,280,110,258,272,246,394,148,243,443,428,1,230,76,50,463,53,173,217,335,355,249,406,228,36,119,174,160,128,410,246,439,375,94,292,232,105,462,223,409,152,435,416,342,297,488,331,250,391,456,52,378,420,387,140,184,124,187,396,440,139,374,272,29,347,329,374,390,247,3,408,330,295,156,21,280,335,294,493,76,294,498,389,278,374,410,279,109,436,154,165,68,413,490,319,474,113,386,51,93,351,480,24,446,469,403,36,395,294,199,68,89,259,471,235,292,117,196,195,353,439,133,243,490,467,41,126,46,446,446,357,277,430,485,364,317,307,75,474,88,269,303,185,254,484,485,276,128,59,95,76,113,139,422,112,295,58,13,370,199,47,8,41,262,88,203,464,417,457,471,46,109,344,187,300,61,298,252,150,352,109,168,306,301,230,9,466,463,248,252,343,269,491,339,202,283,43,190,499,53,140,382,294,304,335,116,464,218,348,182,287,334,137,129,455,359,477,410,217,20,360,320,338,47,111,454,279,111,372,366,215,40,397,138,372,247,86,110,256,112,177,311,98,191,86,485,352,210,294,496,51,434,54,121,62,66,317,346,15,447,174,424,211,252,384,153,128,365,201,235,143,143,205,293,498,211,169,387,453,281,474,405,476,452,158,190,238,147,406,83,194,496,208,244,310,354,257,407,205,98,242,90,494,210,492,298,287,483,100,414,407,351,79,285,466,60,407,466,371,236,41,85,234,198,394,426,94,250,19,16,398,230,94,2,417,335,416,17,259,56,290,434,480,74,447,500,373,224,78,382,358,357,106,334,42,467,104,335,436,346,376,109,293,325,149,55,159,307,398,278,476,72,285,20,218,368,451,35,222,248,64,368,341,62,337,141,280,138,141,342,234,175,299,169,428,184,120,473,10,499,438,149,376,39,430,7,27,30,484,366,311,231,443,259,40,389,175,120,248,280,160,50,234,408,437,345,145,259,291,486,269,331,449,235,185,349,368,234,268,404,170,363,39,31,438,311,478,282,497,166,23,363,218,157,392,498,138,257,412,94,300,486,434,226,416,315,120,381,317,434,313,146,235,276,307,434,225,260,394,230,360,462,430,147,89,106,232,184,424,175,42,465,216,487,337,322,362,146,97,342,64,201,414,158,54,17,241,376,52,387,467,260,32,221,49,295,192,210,400,499,387,144,376,102,490,208,376,325,496,124,409,347,430,335,368,378,463,479,84,8,328,122,243,492,393,164,309,329,247,43,208,134,132,470,453,391,130,294,414,429,390,251,83,293,402,116,328,119,277,404,410,322,321,40,187,486,339,11,85,181,312,240,167,256,431,101,331,401,359,366,217,8,305,78,400,477,156,334,442,446,404,492,366,268,366,242,117,485,325,496,254,235,61,486,301,389,56,81,64,125,199,25,300,459,79,346,149,156,152,323,358,289,484,91,103,303,201,327,393,4,300,376,277,402,379,442,319,320,163,91,476,105,453,196,226,222,472,488,84,160,239,176,179,403,203,127,105,191,117,242,117,479,403,326,481,192,142,260,412,100,345,291,175,435,201,20,224,24,340,71,144,101,482,331,438,27,379,305,1,370,75,188,252,259,15,48,107,145,375,175,381,256,455,97,407,473,473,127,314,298,399,499,257,367,475,323,446,157,286,241,369,96,198,346,257,231,52,223,192,98,125,320,239,410,283,194,67,56,90,132,208,232,418,178,268,70,9,481,233,134,150,466,499,452,351,128,200,392,398,48,268,322,414,137,268,499,96,269,421,186,412,18,111,42,276,96,88,266,182,9,175,24,16,339,299,72,309,110,53,447,421,27,75,486,150,471,267,144,363,112,25,241,193,307,98,297,231,56,230,151,155,464,296,252,286,193,147,175,182,213,375,295,428,479,123,314,85,354,222,477,476,98,351,262,100,464,408,414,288,397,168,157,32,17,179,468,292,217,213,443,280,95,69,306,304,15,185,450,448,473,396,107,304,322,268,69,97,470,72,140,156,377,442,365,295,139,3,259,355,14,9,435,239,150,439,418,483,23,227,369,172,232,214,429,365,311,416,399,84,238,268,393,29,71,298,51,417,66,406,151,124,304,405,205,41,4,444,224,137,346,390,405,120,249,425,468,464,493,370,320,342,384,217,476,183,371,472,341,264,458,194,188,288,223,22,177,18,226,253,220,470,395,195,148,393,217,146,488,369,157,409,488,428,140,129,488,50,280,269,48,290,7,300,53,369,49,164,348,278,97,161,20,145,147,254,470,256,388,466,339,72,236,327,36,446,305,71,345,65,340,461,379,372,263,24,84,406,262,323,433,96,494,50,472,428,104,120,194,123,105,365,72,257,378,394,122,218,155'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "','.join([str(random.randint(1, 500)) for _ in range(5000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[26, -71],[-35, -63],[96, 23],[82, -79],[-45, 87],[-81, 91],[18, 63],[-56, 82],[98, -84],[-7, -75],[44, -75],[-4, 8],[-27, -6],[-86, -96],[3, 37],[-22, -94],[-39, -1],[38, -15],[-15, -70],[-61, -81],[-47, 63],[45, 30],[-14, 5],[68, 43],[-65, -10],[59, -19],[68, -86],[-75, 73],[11, 28],[-58, 17],[88, -39],[-77, -23],[17, -35],[0, -93],[12, -70],[34, -94],[27, 93],[50, -66],[14, 97],[17, -1],[-47, -22],[-73, 74],[43, 100],[-71, 56],[36, 11],[67, 19],[-9, 58],[-72, -38],[47, 95],[89, 53],[6, 92],[-99, 56],[-37, 11],[-47, 100],[3, 74],[-73, -87],[-80, -92],[64, -53],[-6, 62],[9, 67],[35, 46],[36, -47],[70, -22],[-12, 24],[-19, 43],[-41, 64],[-84, 48],[11, -80],[37, 90],[-63, -51],[54, -5],[95, -90],[-25, 53],[4, 91],[100, 68],[-46, -47],[78, -55],[18, -48],[39, 9],[-68, -83],[89, -7],[62, -23],[-85, 27],[-73, 31],[-92, -55],[33, -63],[88, 47],[25, -9],[-96, 47],[-75, -59],[-32, -83],[-32, -40],[-80, 12],[76, 58],[98, -98],[-30, -46],[-85, 20],[24, -45],[36, -95],[-7, -43]'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "','.join([str([random.randint(-100, 100),random.randint(-100, 100)]) for _ in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'-1'.isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(6/-123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0009814799009985492"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(23 / -23434)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0009814799009985492"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "23 / -23434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0009814799009985492"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-23 / 23434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0009814799009985492"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(23 / 23434)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{inf: 2}\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "tdict = {}\n",
    "tdict[math.inf] = 1\n",
    "tdict[math.inf] += 1\n",
    "print(tdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdict[-0.0] = 234\n",
    "tdict[0.0] = 23123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{inf: 2, -0.0: 23123}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "math.pow(0, 2)\n",
    "math.pow(2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'asdf': 2323}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'asdf': 2323}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fdsa;'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "';asdf'[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 << 31) % 6 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7\n",
      "-5\n",
      "-10\n",
      "8\n",
      "-10\n",
      "-4\n",
      "3\n",
      "-4\n",
      "-7\n",
      "-9\n",
      "6\n",
      "7\n",
      "-1\n",
      "-6\n",
      "-4\n",
      "3\n",
      "-5\n",
      "9\n",
      "1\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):a\n",
    "    t = random.randint(-10, 10)\n",
    "    print(t if t != 0 else 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"913725630286854126\"\n",
      "\"188311830977399845\"\n",
      "\"556516765683311597\"\n",
      "\"649308201484735507\"\n",
      "\"972700636140441909\"\n",
      "\"591683458947262673\"\n",
      "\"613203396175981802\"\n",
      "\"684830436697611268\"\n",
      "\"757683996369211159\"\n",
      "\"679346364356288549\"\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for _ in range(10):\n",
    "    print('\"' + str(random.randint(1, 1000000000)) + str(random.randint(1, 1000000000)) + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], [4, 5, 6, 7, 8, 9, 10, 11, 12, 13], [5, 6, 7, 8, 9, 10, 11, 12, 13, 14], [6, 7, 8, 9, 10, 11, 12, 13, 14, 15], [7, 8, 9, 10, 11, 12, 13, 14, 15, 16], [8, 9, 10, 11, 12, 13, 14, 15, 16, 17], [9, 10, 11, 12, 13, 14, 15, 16, 17, 18], [10, 11, 12, 13, 14, 15, 16, 17, 18, 19], [11, 12, 13, 14, 15, 16, 17, 18, 19, 20], [12, 13, 14, 15, 16, 17, 18, 19, 20, 21], [13, 14, 15, 16, 17, 18, 19, 20, 21, 22], [14, 15, 16, 17, 18, 19, 20, 21, 22, 23], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
    "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [2, 3, 4, 5, 6, 7, 8, 9, 10, 11]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.995200412208242"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.tan(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025005209635746147"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.tan(1/40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[19, 18, 17, 16, 15, 14, 13, 12, 11, 10]\n",
      "[20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
      "[39, 38, 37, 36, 35, 34, 33, 32, 31, 30]\n",
      "[40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "[59, 58, 57, 56, 55, 54, 53, 52, 51, 50]\n",
      "[60, 61, 62, 63, 64, 65, 66, 67, 68, 69]\n",
      "[79, 78, 77, 76, 75, 74, 73, 72, 71, 70]\n",
      "[80, 81, 82, 83, 84, 85, 86, 87, 88, 89]\n",
      "[99, 98, 97, 96, 95, 94, 93, 92, 91, 90]\n",
      "[100, 101, 102, 103, 104, 105, 106, 107, 108, 109]\n",
      "[119, 118, 117, 116, 115, 114, 113, 112, 111, 110]\n",
      "[120, 121, 122, 123, 124, 125, 126, 127, 128, 129]\n",
      "[139, 138, 137, 136, 135, 134, 133, 132, 131, 130]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for r in [[0,1,2,3,4,5,6,7,8,9],[19,18,17,16,15,14,13,12,11,10],[20,21,22,23,24,25,26,27,28,29],[39,38,37,36,35,34,33,32,31,30],[40,41,42,43,44,45,46,47,48,49],[59,58,57,56,55,54,53,52,51,50],[60,61,62,63,64,65,66,67,68,69],[79,78,77,76,75,74,73,72,71,70],[80,81,82,83,84,85,86,87,88,89],[99,98,97,96,95,94,93,92,91,90],[100,101,102,103,104,105,106,107,108,109],[119,118,117,116,115,114,113,112,111,110],[120,121,122,123,124,125,126,127,128,129],[139,138,137,136,135,134,133,132,131,130],[0,0,0,0,0,0,0,0,0,0]]:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"yebhqpxllztllvvmojipavqjodbuoxnltojrlsnzglfsmygdaixqbhkigobmodoezidfbphxkabkvtiaoxteovsmaaqwuygywpvu\"\n",
      "\"jerbbxmkxddckangvgyychdbvkwkkzcybjwemauucnbdajigqeqnsamttvwzjntwpenrpmsfiqmqhlftnudigrorfbzatigrpvyo\"\n",
      "\"pwbbmqcmiwwbabcgwbwrttwbqrwbybizzkzkgvnvipedhjgbgozfequfcdnvohmsghnzgajunlbpzmwuwwqhniworoipzotjatxg\"\n",
      "\"jydiatcbzyshwiiuoxkvbhfmnougumprorlvsthumgiimfzxjuwlpkskegvtbmabpdldeoqceqeimqxyhtuqfvtntklqymfvkgmb\"\n",
      "\"bzfgfxwochkyckbuvkaamyfdkrovxvpqitacbxchwgrmptpmusobltluihlxhhixrllgbmjnfwpvhetzfpgxejrthmejhnxeundh\"\n",
      "\"odqyrulumqbbglzfhoeeqwkstfnbazhorihcmsxkneqziefddfeyzpgywqxwoyiijcejfqthcoagpeotzfnzkqcczubrllomjbqa\"\n",
      "\"dkhaetbpwbpddlluusfxkxbpsoaqmwdiwfpkqtfyupudxamdtzjgzdhzrfplazdksvcgmlupmzuhmbnfikgyawkkxekdrdxixzus\"\n",
      "\"cumhzeqohkhmecfvioxyjiscytagtzxlgtowsritybicfmideoavtuwzqkdtjhttnomzzfqgfzwcichowgucrmtkeosvytmekxze\"\n",
      "\"pdnlyaddgtphbuncsxjxprcxzgpaxmlkklmjeaqceauaiyyvnnxzsypqyyxowsreohosbeewtsnihgtpowqioyxsuomkxvbsuwwf\"\n",
      "\"zawhvudwgzrqmyljmnfxpcmwjtwoyzlhmpivnyoftkozghwjahfjamldnojfjtkouknrjkoyrzhwrqsmwvgyqupmlbolqtrbgjyw\"\n",
      "\"yidvlxwwrdujnnfbshutldzounnngmtikvdwwpmhyupcavndjxfrzpjqxroqbzqsbijcxqwthjstmduhksfqbxcoepclhofmsqgu\"\n",
      "\"hsvuxtttnopnskojtdpjgbpsysjdbbpvovpdfulsnhxiovzizneqjdjknedyqnzybphyhnhswtrkmuhcvavvasaitkjpnrlpjqka\"\n",
      "\"ghrwpfvexsfnozrczsvhccuoqxvkvlrwcbrbhkamrabhcpmyarfgvrglxsktfnbsnlisitrthctyfenrctjpuvserjvzrqjpzgtu\"\n",
      "\"mglojujmomfefrmdsqbuohadaxrpwuxcjotdlkexyckufgiblbhhoikjedigydkgvpfggxyqglezqletekkzxkqvtmrjhrxotune\"\n",
      "\"nrfsawgxnwssbmcewqzzjajwxpzeeobeykwpyumgoyhbiebfdctzacdcesuspbwomcywaqcqczlujuneijygdatnibtnmuhtzkwf\"\n",
      "\"bzgxsxfsqobohupfroohzpqgrtmxoabnmizxavyxsarcoavnoniwwbwulnibhhunebrtcyxeygsxcfmwpaepsptquajnxsudllcg\"\n",
      "\"kdfyjwulxjrywbnhaeebroezxypkjkxwkimuuyappbgeamdbortbbysujamysoblmykgdfoohpzxhbidivxdovugkyrqusdlcbhq\"\n",
      "\"xrpjapassmsankmecwrqtwqjlkgukjfkkaziipaknvnzkxgfbdchuabnutpaqlkyntcgimnrhcqtgpsptwpdtyuahrjnsjncabuy\"\n",
      "\"regspmvdtehyjkbxphnaeflziwzkdzedynigpubunobfukpuvhabrsjsiawqwnemxiefnywducpeuqyddidqslqxceriphmivjrr\"\n",
      "\"nhbdyftproywtshafbbrsdxinlacaihowptcgfhckwktdnifknnujuyrtprjvpgelwlljexriwrrdnfelkqpsjiwoddbzvrciiod\"\n",
      "\"vgemzkljyqfcdltkunzmrhrxfcyovmmhiyauhjyyrgidvwqziuylzdtescepcztpgqjbcqmkajkywlankpnugwstwkpgjuirufey\"\n",
      "\"mwqwhiqohvugczscpkucrwrfsmezszfrhvyiyfcxeajrdwyywwmnjvzfphhozyovftqddfupexylitndldeiurhmasujqcbhffpz\"\n",
      "\"tbjpkwrfownsrvqxjyduwpufgqoyitakqjlhdhmyeikyqqbsuhtyfyrccxqydqicsouqrujtahxfynhexzvdeiclorpuaeplvrym\"\n",
      "\"dmhwgjgqisujwdsjxpgqhcelozkkzacyengctdagzwcmkpidlfowuamdpempseggwmjmskmshtirtvhhlopygjwsljyxcpigbobv\"\n",
      "\"hkdppejnrktmhzpzchebkgykxdjdawsnipfgvbjblpfbinfijlqrqakjwhrwqlvpgoztgnekeoxbxltdjzuckndqfnpczdkpbafk\"\n",
      "\"krztqdtozlsgxsqbzrerhfrjcnkswcukoylxueeopxinflnvkpkvscuynieifkwmnbnqwmxairwemjetcsoivtnvmhurhbcowbii\"\n",
      "\"hzkanaydwefjgjzfooxyfcisimtkzsosidtbxftfhuzftytbubckgnxdvhbxwtjvomwayebuinvfuiyawexcewkcynoqfckpdtzx\"\n",
      "\"xulahairsrgywdjsywhvyvtipvpjoouzkteexnkmalfomwnouxbkqibzeqwsaxkadnayxrthuarkwjoraqczuqdxihxrrbynnwvx\"\n",
      "\"zqbojfimyyydavcnoxcgomaypfiysrirriobfgxqfglsxvahoumgukzmhqhtyaketwrktxdkwzfuxhybhlenqjjjtlvqqvqizecw\"\n",
      "\"lrmvhmrfhigqvubhghzdwjjnltjhjqeilrvpqnvfwwhkxbvgiovyryodlcuvumovnsogiarvsyealttnprqwyxksumfiooxbupau\"\n",
      "\"srgwtldzooribumrgqtnohorxwocrhzeajytmrjmkwytmuqavneabgcryowntljodyvkssdyctpntspnsmiivsdgcehqcjaaombj\"\n",
      "\"rylqixlaefugscxxganfrkhpfggwgedigxgaketpihibrpvsreofcousaypnoennlsxvmrnzozkmqutjsftzkonacndmfyuorcrl\"\n",
      "\"ifczgjgaiglqbbrkkawreektxsakskojssgjjhnyjgmrwpcrrkxpalxkecuxvsfbjdnuyhtlvhacztyxffewfvrtcdrhhvrplihh\"\n",
      "\"iuvvswoycgnrdpcqnnxrubmxoylravclwkczphkmsmlcgzifmkhxmrudgcmgsicqgcbppsbbicspsbziwfnjescrwbcilqqzpfgr\"\n",
      "\"rdynbpkoqhbnhqqephsqjrkstxlsajeztmgwxzcmrxzevszweelrmvocxovmgifuahvrahypbyykxjyvvncomecwsewmhfsdyret\"\n",
      "\"msxzvllwfhafnlkzbrimsgvlyousfzmjwtsguudiyxzfywjxqnzodcsrdqwnyfyuiwncwzffvcmwpralpyxnwevklobyvvysdxso\"\n",
      "\"zrcykpznevcopyxhmzkofvpawkimlukcpzxkdsyfnambtqqvcfbjcqksmorgjqqrrydgvgiisjynrtxptiyumkybsgilspbdonvc\"\n",
      "\"celfbshvdbtguxpfhnygrinbkouteceqozfnifhlmpaswiojfdrcyuijrvtwhowuseuxvgsywseckqkikspsehpjeaspalguvazw\"\n",
      "\"szowpcyiytjlgyabtcttrfijdofhdaugreungqgxpblmwjhgzylutpxuoqnwcftftscpusifexfwhrxopcedssobmdacracwcpft\"\n",
      "\"djpxlslgdkfwqjbqgyunwvmihjgsuvvyefosoubplbrzxzjnuameuwveehgpruxwdefexmbufwyqewrgrgzvbvrilzxgfhiachof\"\n",
      "\"koivkrzvqgbtnxrmtahnwszxggzlkidteiythpacftkelprckejrrpyjunnafaozyrqmbwjahfiitrskmeqbuohsfsiegpmuvshr\"\n",
      "\"yeqngejxgppofevgdfrujxvahwshpfaupdhbdkvspkwkckhjymbtgdraijzlqrolqzhumhaikmgrpqxwrlgcxusatralcsipczua\"\n",
      "\"kvbkhipgkroetljjnunvzcreiugndrhlbdrgqjdiyvadcbyutubewepgvedirvyxqlrhwograapianyzpoobctsugsuwxrxvtprz\"\n",
      "\"ezzemtdlbcbvrzqgrwgjoekrmidgptzkubonxnkqqttsnchybgndwcmevgypcuzlljvkujdnaasyvcdonbofuoacnhmnkmjubejm\"\n",
      "\"trzcjmgrtmxblhvfrdkkhasrjpexpggfakwruxxlynllnkfuupdvlxumpjjszxtsneqqppokihjfuvcbjyceblpwkacroblyjfcu\"\n",
      "\"ddxindxoabjsttpnxtajkkixvmzojfydtqwuxtonghcicybwuvorrmmenwwuqsrbqcbymdualvhwwypmlybyfkfgzhmuysczvlgr\"\n",
      "\"cikpqtkwspeuvshvkbqjjlezfkgyokwmlkstixqucrumdetnnfyupyxaogobjzzcbjtyqvnfbjqtqgqcapnedonelcpveghgcrbb\"\n",
      "\"psngnwbolvxefmtrkvgoltpafymevpehkmctrduynjilzkxikvupitkhiqozdwugfszcnpidcvezjkkcdcvnvenybpgrbbgqqmav\"\n",
      "\"svbnzlyowpwijvurnogjxjbaxpnbzdwvntcltlnuhhkwwrsvrfwsycmczyaikmggvvdcbzrtdhrmvztqccjtnzynenypmrebqxtc\"\n",
      "\"bfvbqwtvuwuvtppimbuldwzbffrtkzlkisqlszkibpfegvjhkgiaupkgxnyqlmygpefhsddkkvuahexibihzbydygvwsvnbnftjh\"\n",
      "\"xkvhawqfeprthlpsqwsurcjevwtncjzvnbsqjgsgcfllvyzxrqqvohmnomoxycjbgfmjqpopfwpezqnhufhhowmzdpzatcwbwuyp\"\n",
      "\"hcnxboxkovjdfegncvzcwjcfoqyjwtqzzpktygqfeemammhnclsqjozwetzmfxnwuoolimgkxxrmsatycxsrotbuegccqpcfzzxg\"\n",
      "\"ezpmgizadxuasurcumxipjkhponpaimjwixuojimvvyibkhbkottbbfofwjxvzudsepehjvhrfmjvrzertanghetvfvnfsvdielb\"\n",
      "\"eqkzolxzevzjygdvjoappiqckdovuqpenbzhzwbeslwgsxekdgiyvdtydbieuopwjaonprkvlvsciqyheipjycpkvvmiehoezvyl\"\n",
      "\"lgezmgtrxxsxolopqkfrvwtqjdguqqtzhwpjybcsypoejlhxnbjispeswzvinrzmvtafemryofrotintrdmtptumqpfyjkptlzyt\"\n",
      "\"sxkxnpteqhhruaytybkzqzqrtlzfoziyivmuvrwebtkuuqtzcfndspudxrqkvhfhyazdfnapxybiovdcyprxxwlqnaycyuvotxpo\"\n",
      "\"jkczzrbpultztcjqmgxvyfauwrsfgichteoljffmbofjkxlfbroumvwxzoamnkgiizmrxazlqmyxlfswyqselurzcmgclttvlxcu\"\n",
      "\"pvphwsfytjddlvkpqyvldzarfdxwriqrdwubutmgvepsnkdlzwxiwhpneqmjvhcewldsvmnqztcogtvoliqjceigmmchaclrmgnt\"\n",
      "\"vyupuworepvtyqxbqfdtoxnlrthokpstxvzmntrimltcsowccjxnamoibvmsrrdkyhxatprywmpqsdizexofcmipymbzhkqjancb\"\n",
      "\"kiztshzrrzvkutoauumvpimjwbgsxnnqonvtdhxgtzhpsseaaejflvxwbalkmuywhkwagapehctaqxoocfkatbayrffyizfzsoyq\"\n",
      "\"bliovletxvwspkwndqjpvstckolrdmgytbyicaerqpaxbyvqfbyhdrmxewhpxelwjigwjdbgebrrhwcopplhmebscgiaxbhcqejx\"\n",
      "\"tppxotyzbwnciwidftrfslqsctbasoewllghpitzpcayxusovveqbljahvzrqdkwmjicrziulpgwurjfpthokehrhzjyqoyvjjnl\"\n",
      "\"pkmbvfgfacvmhxinqbocxclmfdysuatjirfkzdfqjtalmzupapzelqsukmyqsrviidsbvmzarneidskcnufejjunivxxotgtshfc\"\n",
      "\"dnsatwcnfhiflpzlrocxanmrsgpnjktlvkerkquwfpwpclwfsngecfycxeodrhoxkcxahttbusufhmvrotllnuipqosvfpwlagfk\"\n",
      "\"lfvpgbfszwcrdfoplirwkwucvmwigakhtxmcpeumthabrxjqfrzudmgqsgdgcxjkceeekmnpisoqetqwszwixitodmdmmoikbzkm\"\n",
      "\"xyltrgnpzwxymnwdatqoicyhvfgxzhgasyuyofimbszwhorxxymfwbpptmmlhdcmzqmafvmsvhraujubwghlclaetvlpiyqurbqf\"\n",
      "\"mtuwitrygmtpehzpfagitqgmtursgrqntixnkmnrtufhrimafuidwgxxjkxjterphymninycyruokjvaxarzqqtaiyjjzlnmkeyr\"\n",
      "\"vkzsrqjdbmosplwxcqrlxpjaeltrvqqhtiiygnyhvbrsggplidvovbdmyqqvbddyshkdpgculxdvdojkumheptpjiwktvsteizxj\"\n",
      "\"uhujjkymipdgsryucyadcudacnvvcjppspmobtnntnrtiwcolysrfrgysbvszbahofxqcdjpfxjaoknsqxhvqiylxgonoixfjjdv\"\n",
      "\"lhadvnyfqkjpekhbzstidyybjhoeutdhcfxynpsccabjymjqtvcgviodoatkbunikorssxgzglhyzsplaqvprojigxfgxejopugt\"\n",
      "\"rihpgnpfzubpjfcosogyuipllxrfnjlknrdefkxhnafrgrfojpedkohchyavzevigvocsazzcqruwuwnrzbpacwzkpxfvxmctchu\"\n",
      "\"pdmkbtamswrpzwptntuvfrmbabnmbblzawfpjpilmvavqmtwtwokukbncyperjwffcangepvlbjolgweftkyafqirsjhbarrqmlc\"\n",
      "\"ratqwonbavhktooukpskfjzdocsawcqramffnvbzozgkssuasjrnjursqptwqstkhwhktbwusjovfsllkswdbulcouavcrubqzhd\"\n",
      "\"oxgkmwqpxvzaxtumkzycrsohmtemscktxgwbfxmtllmmtotghbmlkeungvjfruncbbvjkwsevxpipgpzdmbavqscdnumieiafpmy\"\n",
      "\"kbmzniaydndwurxgaqknaudfwlebaegfsxpwagpalwvpizntbrlqifellsycfzgzettobnepehanjukgdmalxumrthrqlijcyewe\"\n",
      "\"zpmaoestlppcqjytvuvfpmlaxwmbktedogpnswglajpjvabeqnyfbmloqjdrkkndkkswlvpimizljiwfwyujuoxtucqvofgbqwfw\"\n",
      "\"zgfxcixxsufusoptmubiayuiyfrievlxbknhtnqhnffsrbpzkyhwfrzbkkgoattzhtdmtpweyfujmabdddyrrsirtjxqhktvzvow\"\n",
      "\"kjfhqjxxnxfvunnszxkikbdrlllbsyfnhfsrukhyjyimrhabktowhjvchbxxynlhgjzvvttjsltcpvyxgfecmrrccqbwvtpcirwb\"\n",
      "\"wabckjhamnwasxasxvkgcqixkmvmvzpydmxpywbqbxtosbpzuqzdvhekkxvtvtosonyjxihlirbgwhbqmunkgfdnmozpcesbzgfa\"\n",
      "\"qjrnjarlsmusektcwsbltrojqnbbqzqovpbizcjajtogljfahcsigunztievyvtlozwaepfostphczkxfoprqdeezskcjhbfevzo\"\n",
      "\"rfcfgvohozokflfidpgztpmemuajdyvvaavuwdoyobqcsbsfwvdikqsoqzmsdjjcykjhgfhsnqeepnoulvymxflkvlarkjlgpyxq\"\n",
      "\"ehbvejmssomnmflcgyygdvszddnpymheugjnghnzwostvlbratktfdexncnodhvmivwvwkmedphswawxpbnvdtsyzywsajkqiqke\"\n",
      "\"dwtitvavgyttomkdsfmnalzitdiowlsvtssuyjyzzurlrnyivmkhfvhnyxqpujpchthyxhqhrsnigojtwiklqxioekeiwjgaqkhe\"\n",
      "\"zwnjhayvapampktieczlkyjgsvmcwarqzrcochtvszxqxcruhsrfesgswrzlouczkhoenybwvmsuobaaxfncoiasvlrksfygjgvu\"\n",
      "\"ybrpnosqqtlrmqarysndqvsyqdtmeknpkdecpacmcecouflubqjxzkfhqijioytqszgszorhbkqougizkcewipdsforqhvgjtyux\"\n",
      "\"kxyvicmkoxzpstganzzbzprigzkfncwujrjalxxxhwfxrslorhgvfdxcnthuwhjguhxcpytplwmwxqnksubhwosqxnaugzgankpx\"\n",
      "\"dgznmxbukjgaaljdadsghldevsumhlwuvpdukkpjfboghnerhfodpjfqjynjqvtqmiweyhxkgsodbbijjfodjgwdqhjqygevlgzo\"\n",
      "\"iyksgpfvowtcaptygwzdahrxokvexmxdnatfaiaugicwmtqtzkbibgvuzognmaatxckkqmslbyoehlirlfgcrpcjpbyuculecabs\"\n",
      "\"rpekjmbxwzhjjetsqbskvpbgnudcnfmvgzppjmdksozueowcwkfsrecoubrzwquaosoayzandpmnwwbhfwtgctqsevznhsusqfnh\"\n",
      "\"phhdpoofzmoiokylhcwyecjqnfvqojaqjitsiuibkgxrwtrwokpzkgmpirwuwlajzrrpkhjlpabqgfzrwbfkcvphfxutoyjtfpsk\"\n",
      "\"pylhqutdgxmxsukikgijnldpygvepjrdivndixrcuofswgxjtqpxvncybgsgtqblmxrezfeybefqklefvlevwqhhmunexqwgmxgd\"\n",
      "\"sgvumbmxcmjxokpdirrrfpxwjharodzoxflyljzlnbvbbsjuttrmmlagpgmjnbfsppdbccpmoqltskyeiuwxwhiqbqfqapnoqsvg\"\n",
      "\"uldozauvzobepmtxvkwrnrsrcxqptepcxkgixgkanhqownipvmvpqjysduenjxrfdlfnwvgieyxqfvvhxokswkehwhdzdqdctsdo\"\n",
      "\"qxbqxzqmnzdygkjryjpuwdlzwmmqmgaijywuasmkplvmuufdkafadbrrhfztorilqtvyftalszvpchbhgmeydkzcsxqocxwlwcpq\"\n",
      "\"zcnfriehjstprziifyvhkgcgcgvzaxoelnelplfzbhmifnwisxqzzpuuoxypfebedbxddshxsdbhhasgoibnlprzbwbratjgcxzy\"\n",
      "\"rccvtpwzbuogbpuobueqrngzutfotbydtcxeyunckkfbkcodpspduvidmtnbelbimvcksdssthgngicuummtwjaiuumsmbilejpq\"\n",
      "\"blmexeynkttnrfcrdpwojynlfshuwmoehuwmkmdlfbpckggrdcbczcpnazkfepfbreqaasoaqxqzynvrajqkcmpkmjtdushcmdpj\"\n",
      "\"aiqtuaxdornithdkckimbqjaphhfcsfxanjoxnkvigzyeiadlzmfhuteanauffxstutjtfjuazrftbcnassfwecbwbgsudgegxwy\"\n",
      "\"tszlljavfscqadezcufqjjntzxqjbfvhaibadpfxzzcpmvbzepafocbdttapmpuvznqufhfgipzqoguqmrpidjqcsfzaynteugke\"\n",
      "\"vodcbvcdocbgjwpljmkjzpelhqcvyeycmsfnsmlchaugfhziirodtwgnmgsqhganmnkphdebowzbdgcinbffbizkpudprsrdnqcl\"\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for _ in range(100):\n",
    "    print('\"' + ''.join([chr(random.randint(ord('a'), ord('z'))) for _ in range(100)]) + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,4,2,4,4,3,1,1,3,1]\n",
      "[4,3,3,2,3,3,3,2,4,4]\n",
      "[3,1,2,3,1,2,2,4,2,2]\n",
      "[2,3,1,1,3,1,1,4,1,2]\n",
      "[2,4,4,1,2,3,2,4,1,4]\n",
      "[4,4,4,3,1,1,1,1,3,3]\n",
      "[3,4,3,1,1,3,1,2,4,3]\n",
      "[2,4,1,3,3,4,2,2,2,2]\n",
      "[1,3,3,2,1,4,2,4,3,4]\n",
      "[2,1,4,2,2,3,4,4,2,3]\n",
      "[3,3,1,3,1,1,4,4,1,3]\n",
      "[3,3,3,1,4,2,4,4,1,4]\n",
      "[3,2,3,2,4,2,4,1,4,3]\n",
      "[1,1,2,1,2,3,1,3,4,1]\n",
      "[4,1,3,1,4,2,2,2,4,3]\n",
      "[1,3,2,1,2,1,2,4,3,3]\n",
      "[3,2,4,2,1,2,1,3,2,1]\n",
      "[1,4,3,3,3,1,4,3,4,1]\n",
      "[3,1,2,4,1,1,1,1,4,3]\n",
      "[3,2,2,3,4,2,1,4,4,2]\n",
      "[3,4,2,3,1,2,4,2,1,3]\n",
      "[2,3,3,3,3,4,1,3,2,4]\n",
      "[4,4,4,2,4,1,2,4,4,2]\n",
      "[3,1,1,4,2,2,4,1,1,2]\n",
      "[3,4,4,4,4,2,2,2,1,3]\n",
      "[1,2,3,2,2,4,2,3,4,4]\n",
      "[1,3,3,4,3,2,2,2,1,2]\n",
      "[2,2,2,4,3,2,2,4,4,1]\n",
      "[1,1,3,1,2,2,2,3,1,1]\n",
      "[2,2,1,3,1,4,1,1,3,4]\n",
      "[1,4,2,2,2,3,3,2,2,3]\n",
      "[4,2,3,3,3,3,3,3,4,3]\n",
      "[3,4,3,4,1,1,1,4,2,2]\n",
      "[4,4,4,1,3,3,2,2,3,1]\n",
      "[2,1,4,4,1,2,2,2,2,4]\n",
      "[3,1,3,4,2,2,2,3,4,2]\n",
      "[3,2,2,2,1,1,4,2,3,3]\n",
      "[3,1,2,2,4,4,2,1,1,3]\n",
      "[1,2,1,3,3,4,2,2,2,2]\n",
      "[2,4,3,2,4,4,2,1,2,2]\n",
      "[1,3,2,3,1,1,4,1,1,3]\n",
      "[4,2,3,4,3,2,4,1,2,2]\n",
      "[3,1,1,4,1,1,2,3,2,3]\n",
      "[3,3,3,3,4,4,2,1,1,4]\n",
      "[4,1,4,4,2,1,2,2,2,4]\n",
      "[3,2,3,4,3,4,4,4,4,2]\n",
      "[1,3,3,1,2,2,1,4,3,4]\n",
      "[2,2,2,4,1,2,4,4,3,4]\n",
      "[2,1,3,3,1,4,4,4,2,3]\n",
      "[3,3,4,1,1,1,3,3,4,1]\n",
      "[1,1,2,2,4,3,4,3,2,1]\n",
      "[3,4,2,2,3,3,2,1,1,2]\n",
      "[4,3,1,2,1,2,4,1,2,1]\n",
      "[2,3,1,4,4,2,4,2,1,4]\n",
      "[1,3,3,2,4,3,3,4,1,3]\n",
      "[3,1,3,2,1,2,3,2,3,3]\n",
      "[2,4,3,3,4,3,2,4,3,4]\n",
      "[2,1,2,2,4,4,3,2,2,3]\n",
      "[3,2,4,4,4,1,4,4,3,4]\n",
      "[3,1,3,1,1,4,3,1,4,3]\n",
      "[2,1,2,3,3,3,3,1,4,1]\n",
      "[2,1,3,1,2,4,2,2,3,1]\n",
      "[4,2,3,1,4,3,2,4,1,1]\n",
      "[1,1,1,4,3,2,3,3,3,2]\n",
      "[2,3,3,1,2,2,1,1,3,3]\n",
      "[1,4,4,2,4,2,2,2,2,1]\n",
      "[3,1,2,2,3,3,1,4,1,4]\n",
      "[4,2,3,4,2,4,4,3,3,2]\n",
      "[4,4,4,1,2,1,2,4,2,3]\n",
      "[4,3,3,4,3,2,2,4,4,1]\n",
      "[1,1,1,3,2,4,4,2,4,1]\n",
      "[1,1,4,1,4,4,2,1,1,4]\n",
      "[1,4,4,1,2,2,2,1,2,3]\n",
      "[2,2,2,2,2,1,2,4,2,3]\n",
      "[3,4,4,1,3,2,4,4,1,1]\n",
      "[1,3,4,2,3,1,2,2,3,1]\n",
      "[3,3,3,2,1,2,3,1,3,3]\n",
      "[1,4,4,2,1,2,4,2,4,4]\n",
      "[3,2,1,3,1,1,4,1,2,3]\n",
      "[2,4,1,2,4,2,1,3,3,4]\n",
      "[1,4,1,4,4,3,1,2,2,1]\n",
      "[4,4,3,4,2,3,4,3,4,3]\n",
      "[4,1,1,2,3,4,4,3,4,4]\n",
      "[3,2,2,4,2,4,4,2,3,3]\n",
      "[4,3,4,4,1,1,2,3,2,3]\n",
      "[2,3,3,2,2,2,1,3,4,2]\n",
      "[2,3,3,3,4,4,3,1,4,1]\n",
      "[3,4,3,1,2,4,1,3,1,3]\n",
      "[2,3,1,3,3,2,4,3,4,2]\n",
      "[3,2,3,1,1,3,4,1,1,2]\n",
      "[4,1,4,2,2,4,2,4,4,1]\n",
      "[1,2,2,4,4,3,4,4,3,3]\n",
      "[3,2,3,4,3,1,3,2,2,4]\n",
      "[1,2,3,3,1,1,1,3,2,3]\n",
      "[4,2,3,1,2,3,2,4,3,2]\n",
      "[1,2,1,4,1,4,4,3,1,3]\n",
      "[2,1,3,2,2,3,1,1,4,3]\n",
      "[2,4,3,1,2,4,2,2,3,1]\n",
      "[3,3,4,2,2,1,3,3,3,3]\n",
      "[3,4,1,3,1,2,4,1,1,2]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for _ in range(100):\n",
    "    print('[' + ','.join([str(random.randint(1, 4)) for _ in range(10)]) + ']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.062211848441645e-11"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3**-23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Dropbox\\Project\\LegitProject\\SubjectSentimentModelling\\exploring\\testing.ipynb Cell 78\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Dropbox/Project/LegitProject/SubjectSentimentModelling/exploring/testing.ipynb#Y140sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Dropbox/Project/LegitProject/SubjectSentimentModelling/exploring/testing.ipynb#Y140sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(random\u001b[39m.\u001b[39mrandint(\u001b[39m2\u001b[39m, \u001b[39m9\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Dropbox/Project/LegitProject/SubjectSentimentModelling/exploring/testing.ipynb#Y140sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(random\u001b[39m.\u001b[39mrandint(\u001b[39m1\u001b[39m, \u001b[39m60\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "for _ in range(100):\n",
    "    print(random.randint(2, 9))\n",
    "    print(random.randint(1, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "055ed1be4b0fa29866f2e2aeab85b185190bfa779d52a08d11b266bfb238964b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
